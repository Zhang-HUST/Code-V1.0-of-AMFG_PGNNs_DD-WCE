{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-10-16T17:22:05.279803200Z",
     "start_time": "2023-10-16T17:22:02.521662200Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# 下面注释掉的适合在非Pycharm 的Juypter Notebook上使用\n",
    "# import sys\n",
    "# path = os.path.join(os.path.dirname(os.getcwd()))\n",
    "# sys.path.append(path) # 将所需要的根目录添加到路径\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output as clear\n",
    "# 导入模型\n",
    "from models.supervisedModels.GNNs import GeneralGNNs\n",
    "# 导入小工具\n",
    "from utils.common_utils import printlog\n",
    "from trainTest.datasets.dataset_utils import get_fileName_weights, get_save_path, get_intra_dataloaders, get_print_info, get_pcc_knn_adj_from_dataloader\n",
    "# 导入模型分类性能评价工具\n",
    "from trainTest.train.intra_train_gnns import train_test_intra_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-10-16T17:22:05.289805700Z",
     "start_time": "2023-10-16T17:22:05.273802100Z"
    }
   },
   "outputs": [],
   "source": [
    "### 1. 获取文件路径和文件名的设置\n",
    "file_path = os.path.join(os.path.dirname(os.getcwd()) , 'preProcessing', 'trainData')\n",
    "gait_or_motion = 'gait' # 'gait', 'motion'\n",
    "motion_type = 'WAK' #'WAK', 'UPS', 'DNS'\n",
    "subjects_list_global = list(['01', '02', '03', '04', '06', '31', '32', '33', '34', '36'])\n",
    "\n",
    "### 2. 获取dataloaders的设置\n",
    "total_exp_time = 5 \n",
    "train_batch, valid_batch, test_batch = 32, 32, 32\n",
    "data_list = ['sub_emg_sample', 'sub_angle_sample']\n",
    "feature_list = ['sub_emg_features', 'sub_angle_features']\n",
    "\n",
    "### 3. GeneralCNNs模型构建参数设置\n",
    "node_amount = 15\n",
    "## 3.1. edge_gen_params\n",
    "#      1) max_esr_ratio: TRG图中保留的最大边比例 max_edge_number = math.floor(max_esr_ratio*node_amount); \n",
    "#      2) trg_edge_connect_mode: 'graph_fix' / 'node_fix' 则为max_edge_number; 'node_random'则为random.choice(list(range(1, max_edge_number)))\n",
    "#      3) node_embedding: 节点嵌入，对'node_fix'和'node_random'，设为False较好；对'graph_fix'，可尝试设为True \n",
    "#      4) pcc_kgnn_gen_mode: 'batch_cnn_feature' / 'batch_train_data' / 'train_set'\n",
    "#        'batch_cnn_feature'和'batch_raw_data'是每个batch都生成不同的动态图，计算开销会较大   \n",
    "#        'train_set'是根据所有的训练集数据生成一张静态图，这种模式下，GCNs在处理KNN图和PCC图时，可以先用阈值激活，再赋予可训练的边权\n",
    "#      5) kgnn_ratio: KNN图中K近邻的比例; \n",
    "#      6) pcc_act_thr / kgnn_act_thr / awmf_act_thr: 用于控制边连接是否激活的阈值。具体分析如下：\n",
    "#         6.1) 当pcc_kgnn_gen_mode等于'batch_cnn_feature'或者'batch_train_data'时:\n",
    "#              pcc_act_thr控制单个batch单个样本的PCC是否激活，设置为[0.5-0.9]\n",
    "#         6.2) 当pcc_kgnn_gen_mode等于'train_set'时:\n",
    "#              类似于一种投票机制，如果训练集中有不少于pcc_act_thr比例的样本所对应的PCC或不少于kgnn_act_thr比例的样本KNN图都有某个边连接，则激活. 设置为[0.1-0.9]\n",
    "#         6.3) awmf_act_thr：一种投票激活机制，和可训练的graph_fusion_weight一起控制AWMF。假设有n个图融合，设置为>=1/n, 保证至少有一种图结构\n",
    "#      7) AWMF_type: 多图融合的哪几种图。assert 'TRG' in self.AWMF_type and 4 >= len(self.AWMF_type) >= 2 / assert 4 >= len(self.AWMF_type) >= 2\n",
    "#      8) AWMF之前，要对TRG，PCC和KNN寻优。例如，trg的max_esr_ratio，PCC的pcc_kgnn_act_thr，KNN的kgnn_ratio和edge_act_thr\n",
    "params = {'max_esr_ratio': 0.3, 'trg_edge_connect_mode': 'node_random', 'node_embedding': False, \n",
    "          'pcc_kgnn_gen_mode': 'train_set', 'pcc_act_thr': 0.5, 'kgnn_ratio': 0.5, 'kgnn_act_thr': 0.5,\n",
    "          'awmf_act_thr': 0.5, 'AWMF_type': ['PSK', 'TRG', 'PCC', 'KNN']}\n",
    "## 3.2. 其他params\n",
    "network_branch = 1  #  1) network_branch = 1，只使用原始数据; 2)  network_branch = 2，同时使用原始数据和时域特征.\n",
    "conv_type = 'Conv' # # one of [DNN, Conv, SKConv, ResNetV1, ResNetV2, MobileNetV1, MobileNetV2, MobileNetV3, ResNeSt, ShuffleNetV1, ShuffleNetV2]\n",
    "edge_gen_mode = 'TRG' # 1) 'PSK'; 2) 'PCC'; 3) 'KNN'; 4) 'TRG'; 5) 'AWMF'.\n",
    "edge_weight_mode = 'default' # 1) 'default'; 2) 'learnable'.\n",
    "graph_fusion_mode = 'default' # 1) 'default'; 2) 'learnable'.\n",
    "gnn_mode = 'GATv2Conv'\n",
    "# 空间域： 1）GATConv (2017); 2) TransformerConv (2020); 3) GATv2Conv (2021); 4) SuperGATConv (2021)\n",
    "# 谱域： 5）GCNConv (2016); 6) ChebConv (2016);  7) LEConv (2019); 8)SSGConv (2021).\n",
    "## 3.3. 固定的参数 \n",
    "readout_mode = 'mean' # 1) 'max'; 2) 'mean'; 3) 'fc‘.\n",
    "## 3.4. 数据设置\n",
    "#  psk邻接矩阵的路径: 获取当前文件所在目录os.getcwd()的上一级目录os.path.dirname(),即’models'，再进入'models\\commonBlocks'\n",
    "psk_path = os.path.join(os.path.dirname(os.getcwd()) , 'models', 'commonBlocks')\n",
    "#  edge_gen_mode in ['PCC', 'KNN'] and params['pcc_kgnn_gen_mode'] == 'train_set': 计算pcc_adj和kgnn_adj\n",
    "pcc_kgnn_adjs = None\n",
    "\n",
    "### 4. 模型训练和测试的参数设置\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "## 4.1. 迭代次数、初始学习率、优化器、学习率衰减、早停和损失函数的设置\n",
    "# 1)'epoch': int, 最大训练轮数\n",
    "# 2)'initial_lr': 初始学习率，默认0.01\n",
    "# 3)'optimizer': 优化器，默认'Adam'，one of ['Adam', 'RMSprop']\n",
    "# 4)'lr_scheduler': 学习率衰减，scheduler_type: one of ['None', 'StepLR', 'MultiStepLR', 'ExponentialLR', AutoWarmupLR', \n",
    "#                                                   'GradualWarmupLR' ,'ReduceLROnPlateau']\n",
    "# 5)'early_stopping': 早停\n",
    "# 6)'criterion': 'loss_type', 默认'CE'('CrossEntropy')，one of ['CE', 'WeightedCE', 'FL'('FocalLoss'), 'WeightedFL', 'AttenuationWeightedCE', 'AttenuationWeightedFL']\n",
    "#                'modify_type': 'exponent' / 'linear'\n",
    "max_epoch = 100\n",
    "callbacks = {'epoch': max_epoch,\n",
    "             'initial_lr': 0.01,\n",
    "             'optimizer': 'Adam',\n",
    "             'lr_scheduler': {'scheduler_type': 'GradualWarmupLR',\n",
    "                              'params':{\n",
    "                                  'StepLR':{'step_size': int(0.2*max_epoch), 'gamma': np.sqrt(0.1)},\n",
    "                                  'MultiStepLR':{'milestones': [int(0.2*max_epoch), int(0.4*max_epoch), int(0.6*max_epoch), int(0.8*max_epoch)], \n",
    "                                                 'gamma': np.sqrt(0.1)},\n",
    "                                  'ExponentialLR':{'gamma': 0.9},\n",
    "                                  'AutoWarmupLR':{'num_warm': 10},\n",
    "                                  'GradualWarmupLR':{'multiplier': 1, 'total_epoch': 10},\n",
    "                                  'ReduceLROnPlateau':{'mode': 'max', 'factor': np.sqrt(0.1),\n",
    "                                                       'patience': 5, 'verbose': False,\n",
    "                                                       'threshold': 0.0001, 'min_lr': 0.00001},\n",
    "                              }\n",
    "                              },\n",
    "             'early_stopping': {'use_es': True, 'params':{'patience': 20, 'verbose': False, 'delta': 0.0001}},\n",
    "             'criterion': {'loss_type': 'AttenuationWeightedFL', 'params':{'modify_type': 'exponent', 'exponent_factor': 5}}}\n",
    "\n",
    "## 4.2. 训练和测试过程中的画图和保存设置\n",
    "# 1) use_tqdm: 为True使用进度条在进度条内打印输出，为False使用hiddenlayer的History打印输出\n",
    "# 2) train_plot: 是否使用hiddenlayer的Canvas为训练过程画图\n",
    "# 3) print_interval: 多少个epoch打印一次输出或更新一次tqdm\n",
    "# 4) model_eval: 使用验证集和测试集评估模型前是否打开model.eval()\n",
    "# 5) test_metrics: list, 整个训练结束后在测试集上评估的指标 ['accuracy', 'precision', 'recall', 'f1', 'specificity', 'npv']\n",
    "# 6) confusion_matrix: dist, 参考'metrics/get_test_metrics函数'. cmap: 'YlGnBu' / 'Blues'\n",
    "#                     'show_type':  {'cm', 'normalized_cm', 'all'}\n",
    "# 7) tsne_visualization: dist, 参考'visualization/tsne函数'\n",
    "#    'show_type':  'train_set' / 'test_set' / 'all', 'feature_type': 'CNN' / 'Linear'\n",
    "# 8）HMM模型for步态识别。步态分类任务的数据集划分方式 gait_dataset_divide_mode： ['random', 'group_fix', 'group_random']\n",
    "train_test_utils = {'use_tqdm': False,\n",
    "                    'train_plot': False,\n",
    "                    'print_interval': 5,\n",
    "                    'model_eval': {'valid': True, 'test': True},\n",
    "                    'test_metrics': ['accuracy', 'precision', 'recall', 'f1', 'specificity', 'npv'],\n",
    "                    'confusion_matrix': {'get_cm': False, 'params':{'show_type': 'all', 'plot': True, 'save_fig': True,\n",
    "                                                                   'save_results': True, 'cmap': 'YlGnBu'}},\n",
    "                    'tsne_visualization': {'get_tsne': False, 'params': {'show_type': 'all', 'feature_type': 'CNN', \n",
    "                                                                        'save_results': True, 'save_fig': True}},\n",
    "                   'hmm_tools': {'gait': gait_or_motion, 'gait_dataset_divide_mode': 'group_random', 'use_hmm': True}\n",
    "                    }            "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. 以下为测试TRG构图方式的代码"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## 1. 以下为测试TRGRatio的代码\n",
    "\"\"\"\n",
    "total_exp_time = 5\n",
    "gait_or_motion = 'motion' # 'gait', 'motion'\n",
    "motion_type = 'WAK' #'WAK', 'UPS', 'DNS'\n",
    "conv_type = 'Conv'\n",
    "edge_gen_mode = 'TRG'\n",
    "edge_weight_mode = 'default'\n",
    "gnn_mode = 'GATv2Conv'\n",
    "callbacks['criterion']['loss_type'] = 'AttenuationWeightedCE'\n",
    "\n",
    "settings_dict = {'total_exp_time': total_exp_time, 'network_branch': network_branch}\n",
    "params = {'max_esr_ratio': 0.3, 'trg_edge_connect_mode': 'node_random', 'node_embedding': False, \n",
    "          'pcc_kgnn_gen_mode': 'train_set', 'pcc_act_thr': 0.5, 'kgnn_ratio': 0.5, 'kgnn_act_thr': 0.5,\n",
    "          'awmf_act_thr': 0.5, 'AWMF_type': ['PSK', 'TRG', 'PCC', 'KNN']}\n",
    "\n",
    "trg_edge_connect_modes = ['graph_fix', 'node_fix', 'node_random']\n",
    "max_esr_ratios = [0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "# max_trg_edge_number = [1, 2, 3, 4, 6, 7, 9, 10, 12, 13]\n",
    "\n",
    "for trg_edge_connect_mode in trg_edge_connect_modes:\n",
    "    params['trg_edge_connect_mode'] = trg_edge_connect_mode\n",
    "    \n",
    "    for max_esr_ratio in max_esr_ratios:\n",
    "        params['max_esr_ratio'] = max_esr_ratio\n",
    "        model = GeneralGNNs(network_branch, gnn_mode, edge_gen_mode, edge_weight_mode, graph_fusion_mode, readout_mode,\n",
    "                     conv_type, node_amount, gait_or_motion, motion_type, psk_path, params)\n",
    "        model_name = model.get_model_name()\n",
    "        printlog(info=get_print_info(gait_or_motion, motion_type, subjects_list_global), time=False, line_break=False)\n",
    "        basic_save_path = os.path.join(os.path.dirname(os.getcwd()) , 'results', 'Intra-Subject', '4-GNNs-TRGTest', trg_edge_connect_mode, str(max_esr_ratio))\n",
    "        ## 开始训练和测试\n",
    "        for subject_order in range(len(subjects_list_global)):\n",
    "            subject = subjects_list_global[subject_order]\n",
    "            file_name, class_weights, encoded_label_name, raw_label_type, true_labels  = get_fileName_weights(file_path, gait_or_motion, motion_type, subject, subjects_list_global)\n",
    "            save_path = get_save_path(basic_save_path, gait_or_motion, motion_type, model_name, subject)\n",
    "            print('保存结果的绝对路径： ', save_path['absolute_path'])\n",
    "            print('保存结果的相对路径： ', save_path['relative_path'])\n",
    "            \n",
    "            callbacks['weights'] = class_weights\n",
    "            train_test_utils['confusion_matrix']['params']['label_type'] = raw_label_type\n",
    "            \n",
    "            for exp_tim in range(total_exp_time):\n",
    "                clear()\n",
    "                current_exp_time = exp_tim + 1\n",
    "                settings_dict['current_exp_time'] = current_exp_time\n",
    "                printlog(info='当前模型：%s, trg_edge_connect_mode: %s'% (model_name, params['trg_edge_connect_mode']), time=True, line_break=False)\n",
    "                print('max_esr_ratio: %.2f, max_trg_edge_number: %d'% (params['max_esr_ratio'], math.floor(params['max_esr_ratio']*node_amount)))\n",
    "                \n",
    "                printlog(info='当前受试者编号：%s' % subject, time=True, line_break=False)\n",
    "                printlog(info='当前实验次数：%d / %d' % (current_exp_time, total_exp_time), time=True, line_break=False)\n",
    "                train_loader, valid_loader, test_loader = get_intra_dataloaders(file_name, data_list, feature_list, encoded_label_name, total_exp_time,gait_or_motion, current_exp_time, train_batch, test_batch, valid_batch, train_test_utils['hmm_tools']['gait_dataset_divide_mode'])\n",
    "                if gait_or_motion == 'gait':\n",
    "                    print('步态数据集划分方式： ', train_test_utils['hmm_tools']['gait_dataset_divide_mode'])\n",
    "                print('Sample size of train set, valid set and test set are: ', len(train_loader.dataset), len(valid_loader.dataset), len(test_loader.dataset))\n",
    "                model = GeneralGNNs(network_branch, gnn_mode, edge_gen_mode, edge_weight_mode, graph_fusion_mode, readout_mode,\n",
    "                     conv_type, node_amount, gait_or_motion, motion_type, psk_path, params)\n",
    "                model.double()\n",
    "                model.to(device=device)\n",
    "                train_test_intra_model(settings_dict, model, train_loader, valid_loader, test_loader, device, save_path, callbacks, train_test_utils, true_labels)\n",
    "                \n",
    "        # 当一个模型针对所有受试者全部训练测试后， 计算保存所有受试者的平均结果\n",
    "        # 新增一个记录所有受试者的所有测试结果的df1\n",
    "        df1_metrics = []\n",
    "        df2_metrics_mean = []\n",
    "        df2_metrics_std = []\n",
    "        printlog(info='当前模型：%s' % model_name, time=True, line_break=True)\n",
    "        basic_file_path = os.path.join(os.path.dirname(os.getcwd()) , 'results', 'Intra-Subject', '4-GNNs-TRGTest', trg_edge_connect_mode, str(max_esr_ratio))\n",
    "        \n",
    "        for subject_order in range(len(subjects_list_global)):\n",
    "            subject = subjects_list_global[subject_order]\n",
    "            metrics_file_path = get_save_path(basic_file_path, gait_or_motion, motion_type, model_name, subject)\n",
    "            metrics_file_name = os.path.join(metrics_file_path['absolute_path'], 'test_metrics.csv')\n",
    "            # 判断文件是否存在\n",
    "            if not os.path.exists(metrics_file_name):\n",
    "                print(\"受试者：%s 的文件: %s， 不存在！\" %(subject, metrics_file_name))\n",
    "            else:\n",
    "                # 读取每个受试者的test_metrics\n",
    "                print(\"读取受试者：%s 的test_metrics: \" %subject)\n",
    "                df = pd.read_csv(metrics_file_name, header=0, index_col=0)\n",
    "                # ignore_index=True参数用于重置索引，以确保索引是连续的\n",
    "                df1_metrics.extend(df.T.values[:-2, :])\n",
    "                df2_metrics_mean.append(df.T.values[-2, :])\n",
    "                df2_metrics_std.append(df.T.values[-1, :])\n",
    "            \n",
    "        printlog(info='当前模型：%s, 保存所有受试者所有测试指标的平均结果' % model_name, time=False, line_break=False)\n",
    "        df1 = pd.DataFrame(df1_metrics, index=range(1, len(df1_metrics) + 1), columns=df.index)\n",
    "        # 计算平均值并添加到DataFrame\n",
    "        mean_row = df1.mean().to_frame().T  # 转换为DataFrame并进行转置\n",
    "        mean_row.index = ['mean']  # 设置索引名称\n",
    "        df1 = pd.concat([df1, mean_row])\n",
    "        # 计算标准差并添加到DataFrame\n",
    "        std_row = df1[:-1].std().to_frame().T  # 转换为DataFrame并进行转置，排除最后一行(mean行)来计算标准差\n",
    "        std_row.index = ['std']  # 设置索引名称\n",
    "        df1 = pd.concat([df1, std_row]).round(3)\n",
    "        # 保存df1  \n",
    "        dfs_save_path = os.path.dirname(metrics_file_path['absolute_path'])\n",
    "        df1_save_name = os.path.join(dfs_save_path, 'all_metrics_averaged_results.csv')\n",
    "        df1.to_csv(df1_save_name, index=True)\n",
    "        \n",
    "        printlog(info='当前模型：%s, 保存单个受试者测试指标平均的平均结果' % model_name, time=False, line_break=False)\n",
    "        # 保存df2\n",
    "        df2_metrics_mean, df2_metrics_std = np.round(np.array(df2_metrics_mean), 3), np.round(np.array(df2_metrics_std), 3)\n",
    "        df2_metrics = np.array([str(df2_metrics_mean[i, j]) +'+'+ str(df2_metrics_std[i, j]) for i in range(df2_metrics_mean.shape[0]) for j in range(df2_metrics_mean.shape[1])])\n",
    "        df2_metrics = df2_metrics.reshape(df2_metrics_mean.shape)\n",
    "        df2 = pd.DataFrame(df2_metrics, index=['Sub'+i for i in subjects_list_global], columns=df.index)\n",
    "        # 计算平均值并添加到DataFrame\n",
    "        mean_row = np.round(np.mean(df2_metrics_mean, axis=0), 3)\n",
    "        std_row = np.round(np.std(df2_metrics_mean, axis=0), 3)\n",
    "        df2.loc['mean'] = mean_row\n",
    "        df2.loc['std'] = std_row\n",
    "        df2_save_name = os.path.join(dfs_save_path, 'alone_subject_averaged_results.csv')\n",
    "        df2.to_csv(df2_save_name, index=True)\n",
    "        \n",
    "        if gait_or_motion == 'gait' and train_test_utils['hmm_tools']['use_hmm']:\n",
    "            ## test_metrics——hmm.csv处理\n",
    "            # 新增一个记录所有受试者的所有测试结果的df1\n",
    "            df1_metrics = []\n",
    "            df2_metrics_mean = []\n",
    "            df2_metrics_std = []\n",
    "            for subject_order in range(len(subjects_list_global)):\n",
    "                subject = subjects_list_global[subject_order]\n",
    "                metrics_file_path = get_save_path(basic_file_path, gait_or_motion, motion_type, model_name, subject)\n",
    "                metrics_file_name = os.path.join(metrics_file_path['absolute_path'], 'test_metrics_hmm.csv')\n",
    "                # 判断文件是否存在\n",
    "                if not os.path.exists(metrics_file_name):\n",
    "                    print(\"受试者：%s 的文件: %s， 不存在！\" %(subject, metrics_file_name))\n",
    "                else:\n",
    "                    # 读取每个受试者的test_metrics\n",
    "                    print(\"读取受试者：%s 的test_metrics_hmm: \" %subject)\n",
    "                    df = pd.read_csv(metrics_file_name, header=0, index_col=0)\n",
    "                    # ignore_index=True参数用于重置索引，以确保索引是连续的\n",
    "                    df1_metrics.extend(df.T.values[:-2, :])\n",
    "                    df2_metrics_mean.append(df.T.values[-2, :])\n",
    "                    df2_metrics_std.append(df.T.values[-1, :])\n",
    "            \n",
    "            printlog(info='当前模型：%s, 保存所有受试者所有测试指标的平均结果' % model_name, time=False, line_break=False)\n",
    "            df1 = pd.DataFrame(df1_metrics, index=range(1, len(df1_metrics) + 1), columns=df.index)\n",
    "            # 计算平均值并添加到DataFrame\n",
    "            mean_row = df1.mean().to_frame().T  # 转换为DataFrame并进行转置\n",
    "            mean_row.index = ['mean']  # 设置索引名称\n",
    "            df1 = pd.concat([df1, mean_row])\n",
    "            # 计算标准差并添加到DataFrame\n",
    "            std_row = df1[:-1].std().to_frame().T  # 转换为DataFrame并进行转置，排除最后一行(mean行)来计算标准差\n",
    "            std_row.index = ['std']  # 设置索引名称\n",
    "            df1 = pd.concat([df1, std_row]).round(3)\n",
    "            # 保存df1  \n",
    "            dfs_save_path = os.path.dirname(metrics_file_path['absolute_path'])\n",
    "            df1_save_name = os.path.join(dfs_save_path, 'all_metrics_averaged_results_hmm.csv')\n",
    "            df1.to_csv(df1_save_name, index=True)\n",
    "            \n",
    "            printlog(info='当前模型：%s, 保存单个受试者测试指标平均的平均结果' % model_name, time=False, line_break=False)\n",
    "            # 保存df2\n",
    "            df2_metrics_mean, df2_metrics_std = np.round(np.array(df2_metrics_mean), 3), np.round(np.array(df2_metrics_std), 3)\n",
    "            df2_metrics = np.array([str(df2_metrics_mean[i, j]) +'+'+ str(df2_metrics_std[i, j]) for i in range(df2_metrics_mean.shape[0]) for j in range(df2_metrics_mean.shape[1])])\n",
    "            df2_metrics = df2_metrics.reshape(df2_metrics_mean.shape)\n",
    "            df2 = pd.DataFrame(df2_metrics, index=['Sub'+i for i in subjects_list_global], columns=df.index)\n",
    "            # 计算平均值并添加到DataFrame\n",
    "            mean_row = np.round(np.mean(df2_metrics_mean, axis=0), 3)\n",
    "            std_row = np.round(np.std(df2_metrics_mean, axis=0), 3)\n",
    "            df2.loc['mean'] = mean_row\n",
    "            df2.loc['std'] = std_row\n",
    "            df2_save_name = os.path.join(dfs_save_path, 'alone_subject_averaged_results_hmm.csv')\n",
    "            df2.to_csv(df2_save_name, index=True)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. 以下为测试gnn_modes的代码"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## 2. 以下为测试gnn_modes的代码\n",
    "# motion任务：conv_type = 'Conv'; params['max_esr_ratio'] = 0.1; edge_gen_mode = 'TRG'\n",
    "# gait任务：conv_type = 'Conv'; params['max_esr_ratio'] = 0.2; edge_gen_mode = 'TRG'\n",
    "# edge_weight_mode = 'default' (for GCNs和GATs) / 'learnable' (for GCNs)\n",
    "\"\"\"\n",
    "settings_dict = {'total_exp_time': total_exp_time, 'network_branch': network_branch}\n",
    "params = {'max_esr_ratio': 0.3, 'trg_edge_connect_mode': 'node_random', 'node_embedding': False, \n",
    "          'pcc_kgnn_gen_mode': 'train_set', 'pcc_act_thr': 0.5, 'kgnn_ratio': 0.5, 'kgnn_act_thr': 0.5,\n",
    "          'awmf_act_thr': 0.5, 'AWMF_type': ['PSK', 'TRG', 'PCC', 'KNN']}\n",
    "conv_type = 'Conv'\n",
    "edge_gen_mode = 'TRG'\n",
    "gnn_modes = ['GATConv', 'TransformerConv', 'GATv2Conv', 'SuperGATConv', 'GCNConv', 'ChebConv', 'LEConv', 'SSGConv']\n",
    "edge_weight_mode = 'default' # 'default' (for GCNs和GATs) / 'learnable' (for GCNs)\n",
    "    \n",
    "for gnn_mode in gnn_modes:\n",
    "    model = GeneralGNNs(network_branch, gnn_mode, edge_gen_mode, edge_weight_mode, graph_fusion_mode, readout_mode,\n",
    "                 conv_type, node_amount, gait_or_motion, motion_type, psk_path, params)\n",
    "    model_name = model.get_model_name()\n",
    "    printlog(info=get_print_info(gait_or_motion, motion_type, subjects_list_global), time=False, line_break=False)\n",
    "    basic_save_path = os.path.join(os.path.dirname(os.getcwd()) , 'results', 'Intra-Subject', '5-GNNs-GNNModesTest')\n",
    "    ## 开始训练和测试\n",
    "    for subject_order in range(len(subjects_list_global)):\n",
    "        subject = subjects_list_global[subject_order]\n",
    "        file_name, class_weights, encoded_label_name, raw_label_type, true_labels  = get_fileName_weights(file_path, gait_or_motion, motion_type, subject, subjects_list_global)\n",
    "        save_path = get_save_path(basic_save_path, gait_or_motion, motion_type, model_name, subject)\n",
    "        print('保存结果的绝对路径： ', save_path['absolute_path'])\n",
    "        print('保存结果的相对路径： ', save_path['relative_path'])\n",
    "        \n",
    "        callbacks['weights'] = class_weights\n",
    "        train_test_utils['confusion_matrix']['params']['label_type'] = raw_label_type\n",
    "        \n",
    "        for exp_tim in range(total_exp_time):\n",
    "            clear()\n",
    "            current_exp_time = exp_tim + 1\n",
    "            settings_dict['current_exp_time'] = current_exp_time\n",
    "            printlog(info='当前模型：%s, trg_edge_mode构建方式: %s'% (model_name, params['trg_edge_connect_mode']), time=True, line_break=False)\n",
    "            print('max_esr_ratio: %.2f, max_trg_edge_number: %d'% (params['max_esr_ratio'], math.floor(params['max_esr_ratio']*node_amount)))\n",
    "            \n",
    "            printlog(info='当前受试者编号：%s' % subject, time=True, line_break=False)\n",
    "            printlog(info='当前实验次数：%d / %d' % (current_exp_time, total_exp_time), time=True, line_break=False)\n",
    "            train_loader, valid_loader, test_loader = get_intra_dataloaders(file_name, data_list, feature_list, encoded_label_name, total_exp_time,gait_or_motion, current_exp_time, train_batch, test_batch, valid_batch, train_test_utils['hmm_tools']['gait_dataset_divide_mode'])\n",
    "            if gait_or_motion == 'gait':\n",
    "                print('步态数据集划分方式： ', train_test_utils['hmm_tools']['gait_dataset_divide_mode'])\n",
    "            print('Sample size of train set, valid set and test set are: ', len(train_loader.dataset), len(valid_loader.dataset), len(test_loader.dataset))\n",
    "            model = GeneralGNNs(network_branch, gnn_mode, edge_gen_mode, edge_weight_mode, graph_fusion_mode, readout_mode,\n",
    "                 conv_type, node_amount, gait_or_motion, motion_type, psk_path, params)\n",
    "            model.double()\n",
    "            model.to(device=device)\n",
    "            train_test_intra_model(settings_dict, model, train_loader, valid_loader, test_loader, device, save_path, callbacks, train_test_utils, true_labels)\n",
    "            \n",
    "    # 当一个模型针对所有受试者全部训练测试后， 计算保存所有受试者的平均结果\n",
    "    # 新增一个记录所有受试者的所有测试结果的df1\n",
    "    df1_metrics = []\n",
    "    df2_metrics_mean = []\n",
    "    df2_metrics_std = []\n",
    "    printlog(info='当前模型：%s' % model_name, time=True, line_break=True)\n",
    "    basic_file_path = os.path.join(os.path.dirname(os.getcwd()) , 'results', 'Intra-Subject', '5-GNNs-GNNModesTest')\n",
    "    \n",
    "    for subject_order in range(len(subjects_list_global)):\n",
    "        subject = subjects_list_global[subject_order]\n",
    "        metrics_file_path = get_save_path(basic_file_path, gait_or_motion, motion_type, model_name, subject)\n",
    "        metrics_file_name = os.path.join(metrics_file_path['absolute_path'], 'test_metrics.csv')\n",
    "        # 判断文件是否存在\n",
    "        if not os.path.exists(metrics_file_name):\n",
    "            print(\"受试者：%s 的文件: %s， 不存在！\" %(subject, metrics_file_name))\n",
    "        else:\n",
    "            # 读取每个受试者的test_metrics\n",
    "            print(\"读取受试者：%s 的test_metrics: \" %subject)\n",
    "            df = pd.read_csv(metrics_file_name, header=0, index_col=0)\n",
    "            # ignore_index=True参数用于重置索引，以确保索引是连续的\n",
    "            df1_metrics.extend(df.T.values[:-2, :])\n",
    "            df2_metrics_mean.append(df.T.values[-2, :])\n",
    "            df2_metrics_std.append(df.T.values[-1, :])\n",
    "        \n",
    "    printlog(info='当前模型：%s, 保存所有受试者所有测试指标的平均结果' % model_name, time=False, line_break=False)\n",
    "    df1 = pd.DataFrame(df1_metrics, index=range(1, len(df1_metrics) + 1), columns=df.index)\n",
    "    # 计算平均值并添加到DataFrame\n",
    "    mean_row = df1.mean().to_frame().T  # 转换为DataFrame并进行转置\n",
    "    mean_row.index = ['mean']  # 设置索引名称\n",
    "    df1 = pd.concat([df1, mean_row])\n",
    "    # 计算标准差并添加到DataFrame\n",
    "    std_row = df1[:-1].std().to_frame().T  # 转换为DataFrame并进行转置，排除最后一行(mean行)来计算标准差\n",
    "    std_row.index = ['std']  # 设置索引名称\n",
    "    df1 = pd.concat([df1, std_row]).round(3)\n",
    "    # 保存df1  \n",
    "    dfs_save_path = os.path.dirname(metrics_file_path['absolute_path'])\n",
    "    df1_save_name = os.path.join(dfs_save_path, 'all_metrics_averaged_results.csv')\n",
    "    df1.to_csv(df1_save_name, index=True)\n",
    "    \n",
    "    printlog(info='当前模型：%s, 保存单个受试者测试指标平均的平均结果' % model_name, time=False, line_break=False)\n",
    "    # 保存df2\n",
    "    df2_metrics_mean, df2_metrics_std = np.round(np.array(df2_metrics_mean), 3), np.round(np.array(df2_metrics_std), 3)\n",
    "    df2_metrics = np.array([str(df2_metrics_mean[i, j]) +'+'+ str(df2_metrics_std[i, j]) for i in range(df2_metrics_mean.shape[0]) for j in range(df2_metrics_mean.shape[1])])\n",
    "    df2_metrics = df2_metrics.reshape(df2_metrics_mean.shape)\n",
    "    df2 = pd.DataFrame(df2_metrics, index=['Sub'+i for i in subjects_list_global], columns=df.index)\n",
    "    # 计算平均值并添加到DataFrame\n",
    "    mean_row = np.round(np.mean(df2_metrics_mean, axis=0), 3)\n",
    "    std_row = np.round(np.std(df2_metrics_mean, axis=0), 3)\n",
    "    df2.loc['mean'] = mean_row\n",
    "    df2.loc['std'] = std_row\n",
    "    df2_save_name = os.path.join(dfs_save_path, 'alone_subject_averaged_results.csv')\n",
    "    df2.to_csv(df2_save_name, index=True)\n",
    "    \n",
    "    if gait_or_motion == 'gait' and train_test_utils['hmm_tools']['use_hmm']:\n",
    "        ## test_metrics——hmm.csv处理\n",
    "        # 新增一个记录所有受试者的所有测试结果的df1\n",
    "        df1_metrics = []\n",
    "        df2_metrics_mean = []\n",
    "        df2_metrics_std = []\n",
    "        for subject_order in range(len(subjects_list_global)):\n",
    "            subject = subjects_list_global[subject_order]\n",
    "            metrics_file_path = get_save_path(basic_file_path, gait_or_motion, motion_type, model_name, subject)\n",
    "            metrics_file_name = os.path.join(metrics_file_path['absolute_path'], 'test_metrics_hmm.csv')\n",
    "            # 判断文件是否存在\n",
    "            if not os.path.exists(metrics_file_name):\n",
    "                print(\"受试者：%s 的文件: %s， 不存在！\" %(subject, metrics_file_name))\n",
    "            else:\n",
    "                # 读取每个受试者的test_metrics\n",
    "                print(\"读取受试者：%s 的test_metrics_hmm: \" %subject)\n",
    "                df = pd.read_csv(metrics_file_name, header=0, index_col=0)\n",
    "                # ignore_index=True参数用于重置索引，以确保索引是连续的\n",
    "                df1_metrics.extend(df.T.values[:-2, :])\n",
    "                df2_metrics_mean.append(df.T.values[-2, :])\n",
    "                df2_metrics_std.append(df.T.values[-1, :])\n",
    "        \n",
    "        printlog(info='当前模型：%s, 保存所有受试者所有测试指标的平均结果' % model_name, time=False, line_break=False)\n",
    "        df1 = pd.DataFrame(df1_metrics, index=range(1, len(df1_metrics) + 1), columns=df.index)\n",
    "        # 计算平均值并添加到DataFrame\n",
    "        mean_row = df1.mean().to_frame().T  # 转换为DataFrame并进行转置\n",
    "        mean_row.index = ['mean']  # 设置索引名称\n",
    "        df1 = pd.concat([df1, mean_row])\n",
    "        # 计算标准差并添加到DataFrame\n",
    "        std_row = df1[:-1].std().to_frame().T  # 转换为DataFrame并进行转置，排除最后一行(mean行)来计算标准差\n",
    "        std_row.index = ['std']  # 设置索引名称\n",
    "        df1 = pd.concat([df1, std_row]).round(3)\n",
    "        # 保存df1  \n",
    "        dfs_save_path = os.path.dirname(metrics_file_path['absolute_path'])\n",
    "        df1_save_name = os.path.join(dfs_save_path, 'all_metrics_averaged_results_hmm.csv')\n",
    "        df1.to_csv(df1_save_name, index=True)\n",
    "        \n",
    "        printlog(info='当前模型：%s, 保存单个受试者测试指标平均的平均结果' % model_name, time=False, line_break=False)\n",
    "        # 保存df2\n",
    "        df2_metrics_mean, df2_metrics_std = np.round(np.array(df2_metrics_mean), 3), np.round(np.array(df2_metrics_std), 3)\n",
    "        df2_metrics = np.array([str(df2_metrics_mean[i, j]) +'+'+ str(df2_metrics_std[i, j]) for i in range(df2_metrics_mean.shape[0]) for j in range(df2_metrics_mean.shape[1])])\n",
    "        df2_metrics = df2_metrics.reshape(df2_metrics_mean.shape)\n",
    "        df2 = pd.DataFrame(df2_metrics, index=['Sub'+i for i in subjects_list_global], columns=df.index)\n",
    "        # 计算平均值并添加到DataFrame\n",
    "        mean_row = np.round(np.mean(df2_metrics_mean, axis=0), 3)\n",
    "        std_row = np.round(np.std(df2_metrics_mean, axis=0), 3)\n",
    "        df2.loc['mean'] = mean_row\n",
    "        df2.loc['std'] = std_row\n",
    "        df2_save_name = os.path.join(dfs_save_path, 'alone_subject_averaged_results_hmm.csv')\n",
    "        df2.to_csv(df2_save_name, index=True)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. 以下为测试PSK图拓扑生成的代码"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## 3. 以下为测试PSK图拓扑生成的代码\n",
    "\"\"\"\n",
    "total_exp_time = 5\n",
    "gait_or_motion = 'motion' # 'gait', 'motion'\n",
    "motion_type = 'WAK' #'WAK', 'UPS', 'DNS'\n",
    "conv_type = 'Conv'\n",
    "edge_gen_mode = 'PSK'\n",
    "edge_weight_mode = 'default'\n",
    "gnn_modes = ['TransformerConv','LEConv']\n",
    "# gnn_modes = ['LEConv']\n",
    "callbacks['criterion']['loss_type'] = 'AttenuationWeightedCE'\n",
    "\n",
    "settings_dict = {'total_exp_time': total_exp_time, 'network_branch': network_branch}\n",
    "params = {'max_esr_ratio': 0.3, 'trg_edge_connect_mode': 'node_random', 'node_embedding': False, \n",
    "          'pcc_kgnn_gen_mode': 'train_set', 'pcc_act_thr': 0.5, 'kgnn_ratio': 0.5, 'kgnn_act_thr': 0.5,\n",
    "          'awmf_act_thr': 0.5, 'AWMF_type': ['PSK', 'TRG', 'PCC', 'KNN']}\n",
    "  \n",
    "for gnn_mode in gnn_modes:\n",
    "    model = GeneralGNNs(network_branch, gnn_mode, edge_gen_mode, edge_weight_mode, graph_fusion_mode, readout_mode,\n",
    "                 conv_type, node_amount, gait_or_motion, motion_type, psk_path, params)\n",
    "    model_name = model.get_model_name()\n",
    "    printlog(info=get_print_info(gait_or_motion, motion_type, subjects_list_global), time=False, line_break=False)\n",
    "    basic_save_path = os.path.join(os.path.dirname(os.getcwd()) , 'results', 'Intra-Subject', '6-GNNs-PSKTest')\n",
    "    ## 开始训练和测试\n",
    "    for subject_order in range(len(subjects_list_global)):\n",
    "        subject = subjects_list_global[subject_order]\n",
    "        file_name, class_weights, encoded_label_name, raw_label_type, true_labels  = get_fileName_weights(file_path, gait_or_motion, motion_type, subject, subjects_list_global)\n",
    "        save_path = get_save_path(basic_save_path, gait_or_motion, motion_type, model_name, subject)\n",
    "        print('保存结果的绝对路径： ', save_path['absolute_path'])\n",
    "        print('保存结果的相对路径： ', save_path['relative_path'])\n",
    "        \n",
    "        callbacks['weights'] = class_weights\n",
    "        train_test_utils['confusion_matrix']['params']['label_type'] = raw_label_type\n",
    "        \n",
    "        for exp_tim in range(total_exp_time):\n",
    "            clear()\n",
    "            current_exp_time = exp_tim + 1\n",
    "            settings_dict['current_exp_time'] = current_exp_time\n",
    "            printlog(info='当前模型：%s'% model_name, time=True, line_break=False)\n",
    "            printlog(info='当前受试者编号：%s' % subject, time=True, line_break=False)\n",
    "            \n",
    "            printlog(info='当前实验次数：%d / %d' % (current_exp_time, total_exp_time), time=True, line_break=False)\n",
    "            train_loader, valid_loader, test_loader = get_intra_dataloaders(file_name, data_list, feature_list, encoded_label_name, total_exp_time,gait_or_motion, current_exp_time, train_batch, test_batch, valid_batch, train_test_utils['hmm_tools']['gait_dataset_divide_mode'])\n",
    "            if gait_or_motion == 'gait':\n",
    "                print('步态数据集划分方式： ', train_test_utils['hmm_tools']['gait_dataset_divide_mode'])\n",
    "            print('Sample size of train set, valid set and test set are: ', len(train_loader.dataset), len(valid_loader.dataset), len(test_loader.dataset))\n",
    "            model = GeneralGNNs(network_branch, gnn_mode, edge_gen_mode, edge_weight_mode, graph_fusion_mode, readout_mode,\n",
    "                 conv_type, node_amount, gait_or_motion, motion_type, psk_path, params)\n",
    "            model.double()\n",
    "            model.to(device=device)\n",
    "            train_test_intra_model(settings_dict, model, train_loader, valid_loader, test_loader, device, save_path, callbacks, train_test_utils, true_labels)\n",
    "            \n",
    "    # 当一个模型针对所有受试者全部训练测试后， 计算保存所有受试者的平均结果\n",
    "    # 新增一个记录所有受试者的所有测试结果的df1\n",
    "    df1_metrics = []\n",
    "    df2_metrics_mean = []\n",
    "    df2_metrics_std = []\n",
    "    printlog(info='当前模型：%s' % model_name, time=True, line_break=True)\n",
    "    basic_file_path = os.path.join(os.path.dirname(os.getcwd()) , 'results', 'Intra-Subject', '6-GNNs-PSKTest')\n",
    "    \n",
    "    for subject_order in range(len(subjects_list_global)):\n",
    "        subject = subjects_list_global[subject_order]\n",
    "        metrics_file_path = get_save_path(basic_file_path, gait_or_motion, motion_type, model_name, subject)\n",
    "        metrics_file_name = os.path.join(metrics_file_path['absolute_path'], 'test_metrics.csv')\n",
    "        # 判断文件是否存在\n",
    "        if not os.path.exists(metrics_file_name):\n",
    "            print(\"受试者：%s 的文件: %s， 不存在！\" %(subject, metrics_file_name))\n",
    "        else:\n",
    "            # 读取每个受试者的test_metrics\n",
    "            print(\"读取受试者：%s 的test_metrics: \" %subject)\n",
    "            df = pd.read_csv(metrics_file_name, header=0, index_col=0)\n",
    "            # ignore_index=True参数用于重置索引，以确保索引是连续的\n",
    "            df1_metrics.extend(df.T.values[:-2, :])\n",
    "            df2_metrics_mean.append(df.T.values[-2, :])\n",
    "            df2_metrics_std.append(df.T.values[-1, :])\n",
    "        \n",
    "    printlog(info='当前模型：%s, 保存所有受试者所有测试指标的平均结果' % model_name, time=False, line_break=False)\n",
    "    df1 = pd.DataFrame(df1_metrics, index=range(1, len(df1_metrics) + 1), columns=df.index)\n",
    "    # 计算平均值并添加到DataFrame\n",
    "    mean_row = df1.mean().to_frame().T  # 转换为DataFrame并进行转置\n",
    "    mean_row.index = ['mean']  # 设置索引名称\n",
    "    df1 = pd.concat([df1, mean_row])\n",
    "    # 计算标准差并添加到DataFrame\n",
    "    std_row = df1[:-1].std().to_frame().T  # 转换为DataFrame并进行转置，排除最后一行(mean行)来计算标准差\n",
    "    std_row.index = ['std']  # 设置索引名称\n",
    "    df1 = pd.concat([df1, std_row]).round(3)\n",
    "    # 保存df1  \n",
    "    dfs_save_path = os.path.dirname(metrics_file_path['absolute_path'])\n",
    "    df1_save_name = os.path.join(dfs_save_path, 'all_metrics_averaged_results.csv')\n",
    "    df1.to_csv(df1_save_name, index=True)\n",
    "    \n",
    "    printlog(info='当前模型：%s, 保存单个受试者测试指标平均的平均结果' % model_name, time=False, line_break=False)\n",
    "    # 保存df2\n",
    "    df2_metrics_mean, df2_metrics_std = np.round(np.array(df2_metrics_mean), 3), np.round(np.array(df2_metrics_std), 3)\n",
    "    df2_metrics = np.array([str(df2_metrics_mean[i, j]) +'+'+ str(df2_metrics_std[i, j]) for i in range(df2_metrics_mean.shape[0]) for j in range(df2_metrics_mean.shape[1])])\n",
    "    df2_metrics = df2_metrics.reshape(df2_metrics_mean.shape)\n",
    "    df2 = pd.DataFrame(df2_metrics, index=['Sub'+i for i in subjects_list_global], columns=df.index)\n",
    "    # 计算平均值并添加到DataFrame\n",
    "    mean_row = np.round(np.mean(df2_metrics_mean, axis=0), 3)\n",
    "    std_row = np.round(np.std(df2_metrics_mean, axis=0), 3)\n",
    "    df2.loc['mean'] = mean_row\n",
    "    df2.loc['std'] = std_row\n",
    "    df2_save_name = os.path.join(dfs_save_path, 'alone_subject_averaged_results.csv')\n",
    "    df2.to_csv(df2_save_name, index=True)\n",
    "    \n",
    "    if gait_or_motion == 'gait' and train_test_utils['hmm_tools']['use_hmm']:\n",
    "        ## test_metrics——hmm.csv处理\n",
    "        # 新增一个记录所有受试者的所有测试结果的df1\n",
    "        df1_metrics = []\n",
    "        df2_metrics_mean = []\n",
    "        df2_metrics_std = []\n",
    "        for subject_order in range(len(subjects_list_global)):\n",
    "            subject = subjects_list_global[subject_order]\n",
    "            metrics_file_path = get_save_path(basic_file_path, gait_or_motion, motion_type, model_name, subject)\n",
    "            metrics_file_name = os.path.join(metrics_file_path['absolute_path'], 'test_metrics_hmm.csv')\n",
    "            # 判断文件是否存在\n",
    "            if not os.path.exists(metrics_file_name):\n",
    "                print(\"受试者：%s 的文件: %s， 不存在！\" %(subject, metrics_file_name))\n",
    "            else:\n",
    "                # 读取每个受试者的test_metrics\n",
    "                print(\"读取受试者：%s 的test_metrics_hmm: \" %subject)\n",
    "                df = pd.read_csv(metrics_file_name, header=0, index_col=0)\n",
    "                # ignore_index=True参数用于重置索引，以确保索引是连续的\n",
    "                df1_metrics.extend(df.T.values[:-2, :])\n",
    "                df2_metrics_mean.append(df.T.values[-2, :])\n",
    "                df2_metrics_std.append(df.T.values[-1, :])\n",
    "        \n",
    "        printlog(info='当前模型：%s, 保存所有受试者所有测试指标的平均结果' % model_name, time=False, line_break=False)\n",
    "        df1 = pd.DataFrame(df1_metrics, index=range(1, len(df1_metrics) + 1), columns=df.index)\n",
    "        # 计算平均值并添加到DataFrame\n",
    "        mean_row = df1.mean().to_frame().T  # 转换为DataFrame并进行转置\n",
    "        mean_row.index = ['mean']  # 设置索引名称\n",
    "        df1 = pd.concat([df1, mean_row])\n",
    "        # 计算标准差并添加到DataFrame\n",
    "        std_row = df1[:-1].std().to_frame().T  # 转换为DataFrame并进行转置，排除最后一行(mean行)来计算标准差\n",
    "        std_row.index = ['std']  # 设置索引名称\n",
    "        df1 = pd.concat([df1, std_row]).round(3)\n",
    "        # 保存df1  \n",
    "        dfs_save_path = os.path.dirname(metrics_file_path['absolute_path'])\n",
    "        df1_save_name = os.path.join(dfs_save_path, 'all_metrics_averaged_results_hmm.csv')\n",
    "        df1.to_csv(df1_save_name, index=True)\n",
    "        \n",
    "        printlog(info='当前模型：%s, 保存单个受试者测试指标平均的平均结果' % model_name, time=False, line_break=False)\n",
    "        # 保存df2\n",
    "        df2_metrics_mean, df2_metrics_std = np.round(np.array(df2_metrics_mean), 3), np.round(np.array(df2_metrics_std), 3)\n",
    "        df2_metrics = np.array([str(df2_metrics_mean[i, j]) +'+'+ str(df2_metrics_std[i, j]) for i in range(df2_metrics_mean.shape[0]) for j in range(df2_metrics_mean.shape[1])])\n",
    "        df2_metrics = df2_metrics.reshape(df2_metrics_mean.shape)\n",
    "        df2 = pd.DataFrame(df2_metrics, index=['Sub'+i for i in subjects_list_global], columns=df.index)\n",
    "        # 计算平均值并添加到DataFrame\n",
    "        mean_row = np.round(np.mean(df2_metrics_mean, axis=0), 3)\n",
    "        std_row = np.round(np.std(df2_metrics_mean, axis=0), 3)\n",
    "        df2.loc['mean'] = mean_row\n",
    "        df2.loc['std'] = std_row\n",
    "        df2_save_name = os.path.join(dfs_save_path, 'alone_subject_averaged_results_hmm.csv')\n",
    "        df2.to_csv(df2_save_name, index=True)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. 以下为测试PCC构图方式的代码"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## 4. 以下为测试PCC构图的代码\n",
    "\"\"\"\n",
    "total_exp_time = 5\n",
    "network_branch = 1\n",
    "gait_or_motion = 'gait' # 'gait', 'motion'\n",
    "motion_type = 'WAK' #'WAK', 'UPS', 'DNS'\n",
    "conv_type = 'Conv'\n",
    "edge_gen_mode = 'PCC'\n",
    "settings_dict = {'total_exp_time': total_exp_time, 'network_branch': network_branch}\n",
    "gnn_modes = ['TransformerConv','LEConv']\n",
    "\n",
    "# pcc_kgnn_gen_modes = ['batch_cnn_feature', 'batch_train_data', 'train_set']\n",
    "pcc_kgnn_gen_modes = ['train_set']\n",
    "params = {'max_esr_ratio': 0.3, 'trg_edge_connect_mode': 'node_random', 'node_embedding': False, \n",
    "          'pcc_kgnn_gen_mode': 'train_set', 'pcc_act_thr': 0.5, 'kgnn_ratio': 0.5, 'kgnn_act_thr': 0.5,\n",
    "          'awmf_act_thr': 0.5, 'AWMF_type': ['PSK', 'TRG', 'PCC', 'KNN']}\n",
    "callbacks['criterion']['loss_type'] = 'AttenuationWeightedCE'      \n",
    "\n",
    "for pcc_kgnn_gen_mode in pcc_kgnn_gen_modes:\n",
    "    params['pcc_kgnn_gen_mode'] = pcc_kgnn_gen_mode\n",
    "    for gnn_mode in gnn_modes:\n",
    "        if pcc_kgnn_gen_mode == 'train_set':\n",
    "            pcc_act_thrs = [0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "            if gnn_mode == 'LEConv':\n",
    "                edge_weight_mode = 'learnable' \n",
    "        else:\n",
    "            edge_weight_mode = 'default'\n",
    "            pcc_act_thrs = [0.9, 0.8, 0.7, 0.6, 0.5]\n",
    "            \n",
    "        for pcc_act_thr in pcc_act_thrs:\n",
    "            params['pcc_act_thr'] = pcc_act_thr\n",
    "            params['pcc_kgnn_adjs'] = None\n",
    "            model = GeneralGNNs(network_branch, gnn_mode, edge_gen_mode, edge_weight_mode, graph_fusion_mode, readout_mode,\n",
    "                         conv_type, node_amount, gait_or_motion, motion_type, psk_path, params)\n",
    "            model_name = model.get_model_name()\n",
    "            printlog(info=get_print_info(gait_or_motion, motion_type, subjects_list_global), time=False, line_break=False)\n",
    "            basic_save_path = os.path.join(os.path.dirname(os.getcwd()) , 'results', 'Intra-Subject', '7-GNNs-PCCTest', pcc_kgnn_gen_mode, str(pcc_act_thr))\n",
    "            ## 开始训练和测试\n",
    "            for subject_order in range(len(subjects_list_global)):\n",
    "                subject = subjects_list_global[subject_order]\n",
    "                file_name, class_weights, encoded_label_name, raw_label_type, true_labels  = get_fileName_weights(file_path, gait_or_motion, motion_type, subject, subjects_list_global)\n",
    "                save_path = get_save_path(basic_save_path, gait_or_motion, motion_type, model_name, subject)\n",
    "                print('保存结果的绝对路径： ', save_path['absolute_path'])\n",
    "                print('保存结果的相对路径： ', save_path['relative_path'])\n",
    "                \n",
    "                callbacks['weights'] = class_weights\n",
    "                train_test_utils['confusion_matrix']['params']['label_type'] = raw_label_type\n",
    "                \n",
    "                for exp_tim in range(total_exp_time):\n",
    "                    clear()\n",
    "                    current_exp_time = exp_tim + 1\n",
    "                    settings_dict['current_exp_time'] = current_exp_time\n",
    "                    printlog(info='当前模型：%s'% model_name, time=True, line_break=False)\n",
    "                    print('edge生成方式: %s, pcc_kgnn_gen_mode: %s '% (pcc_kgnn_gen_mode, edge_gen_mode))\n",
    "                    print('pcc_act_thr: %.2f'% params['pcc_act_thr'])\n",
    "                    \n",
    "                    printlog(info='当前受试者编号：%s' % subject, time=True, line_break=False)\n",
    "                    printlog(info='当前实验次数：%d / %d' % (current_exp_time, total_exp_time), time=True, line_break=False)\n",
    "                    train_loader, valid_loader, test_loader = get_intra_dataloaders(file_name, data_list, feature_list, encoded_label_name, total_exp_time,gait_or_motion, current_exp_time, train_batch, test_batch, valid_batch, train_test_utils['hmm_tools']['gait_dataset_divide_mode'])\n",
    "                    if gait_or_motion == 'gait':\n",
    "                        print('步态数据集划分方式： ', train_test_utils['hmm_tools']['gait_dataset_divide_mode'])\n",
    "                    print('Sample size of train set, valid set and test set are: ', len(train_loader.dataset), len(valid_loader.dataset), len(test_loader.dataset))\n",
    "                    if edge_gen_mode in ['PCC', 'KNN'] and params['pcc_kgnn_gen_mode'] == 'train_set':\n",
    "                        params['pcc_kgnn_adjs'] = get_pcc_knn_adj_from_dataloader(train_loader, params, edge_gen_mode)\n",
    "                    elif edge_gen_mode == 'AWMF' and ('PCC' in params['AWMF_type'] or 'KNN' in params['AWMF_type']):\n",
    "                        params['pcc_kgnn_adjs'] = get_pcc_knn_adj_from_dataloader(train_loader, params, edge_gen_mode)\n",
    "                    else:\n",
    "                        params['pcc_kgnn_adjs'] = None\n",
    "                    model = GeneralGNNs(network_branch, gnn_mode, edge_gen_mode, edge_weight_mode, graph_fusion_mode, readout_mode,\n",
    "                         conv_type, node_amount, gait_or_motion, motion_type, psk_path, params)\n",
    "                    model.double()\n",
    "                    model.to(device=device)\n",
    "                    train_test_intra_model(settings_dict, model, train_loader, valid_loader, test_loader, device, save_path, callbacks, train_test_utils, true_labels)\n",
    "                    \n",
    "            # 当一个模型针对所有受试者全部训练测试后， 计算保存所有受试者的平均结果\n",
    "            # 新增一个记录所有受试者的所有测试结果的df1\n",
    "            df1_metrics = []\n",
    "            df2_metrics_mean = []\n",
    "            df2_metrics_std = []\n",
    "            printlog(info='当前模型：%s' % model_name, time=True, line_break=True)\n",
    "            basic_file_path = os.path.join(os.path.dirname(os.getcwd()) , 'results', 'Intra-Subject', '7-GNNs-PCCTest', pcc_kgnn_gen_mode, str(pcc_act_thr))\n",
    "            \n",
    "            for subject_order in range(len(subjects_list_global)):\n",
    "                subject = subjects_list_global[subject_order]\n",
    "                metrics_file_path = get_save_path(basic_file_path, gait_or_motion, motion_type, model_name, subject)\n",
    "                metrics_file_name = os.path.join(metrics_file_path['absolute_path'], 'test_metrics.csv')\n",
    "                # 判断文件是否存在\n",
    "                if not os.path.exists(metrics_file_name):\n",
    "                    print(\"受试者：%s 的文件: %s， 不存在！\" %(subject, metrics_file_name))\n",
    "                else:\n",
    "                    # 读取每个受试者的test_metrics\n",
    "                    print(\"读取受试者：%s 的test_metrics: \" %subject)\n",
    "                    df = pd.read_csv(metrics_file_name, header=0, index_col=0)\n",
    "                    # ignore_index=True参数用于重置索引，以确保索引是连续的\n",
    "                    df1_metrics.extend(df.T.values[:-2, :])\n",
    "                    df2_metrics_mean.append(df.T.values[-2, :])\n",
    "                    df2_metrics_std.append(df.T.values[-1, :])\n",
    "                \n",
    "            printlog(info='当前模型：%s, 保存所有受试者所有测试指标的平均结果' % model_name, time=False, line_break=False)\n",
    "            df1 = pd.DataFrame(df1_metrics, index=range(1, len(df1_metrics) + 1), columns=df.index)\n",
    "            # 计算平均值并添加到DataFrame\n",
    "            mean_row = df1.mean().to_frame().T  # 转换为DataFrame并进行转置\n",
    "            mean_row.index = ['mean']  # 设置索引名称\n",
    "            df1 = pd.concat([df1, mean_row])\n",
    "            # 计算标准差并添加到DataFrame\n",
    "            std_row = df1[:-1].std().to_frame().T  # 转换为DataFrame并进行转置，排除最后一行(mean行)来计算标准差\n",
    "            std_row.index = ['std']  # 设置索引名称\n",
    "            df1 = pd.concat([df1, std_row]).round(3)\n",
    "            # 保存df1  \n",
    "            dfs_save_path = os.path.dirname(metrics_file_path['absolute_path'])\n",
    "            df1_save_name = os.path.join(dfs_save_path, 'all_metrics_averaged_results.csv')\n",
    "            df1.to_csv(df1_save_name, index=True)\n",
    "            \n",
    "            printlog(info='当前模型：%s, 保存单个受试者测试指标平均的平均结果' % model_name, time=False, line_break=False)\n",
    "            # 保存df2\n",
    "            df2_metrics_mean, df2_metrics_std = np.round(np.array(df2_metrics_mean), 3), np.round(np.array(df2_metrics_std), 3)\n",
    "            df2_metrics = np.array([str(df2_metrics_mean[i, j]) +'+'+ str(df2_metrics_std[i, j]) for i in range(df2_metrics_mean.shape[0]) for j in range(df2_metrics_mean.shape[1])])\n",
    "            df2_metrics = df2_metrics.reshape(df2_metrics_mean.shape)\n",
    "            df2 = pd.DataFrame(df2_metrics, index=['Sub'+i for i in subjects_list_global], columns=df.index)\n",
    "            # 计算平均值并添加到DataFrame\n",
    "            mean_row = np.round(np.mean(df2_metrics_mean, axis=0), 3)\n",
    "            std_row = np.round(np.std(df2_metrics_mean, axis=0), 3)\n",
    "            df2.loc['mean'] = mean_row\n",
    "            df2.loc['std'] = std_row\n",
    "            df2_save_name = os.path.join(dfs_save_path, 'alone_subject_averaged_results.csv')\n",
    "            df2.to_csv(df2_save_name, index=True)\n",
    "            \n",
    "            if gait_or_motion == 'gait' and train_test_utils['hmm_tools']['use_hmm']:\n",
    "                ## test_metrics——hmm.csv处理\n",
    "                # 新增一个记录所有受试者的所有测试结果的df1\n",
    "                df1_metrics = []\n",
    "                df2_metrics_mean = []\n",
    "                df2_metrics_std = []\n",
    "                for subject_order in range(len(subjects_list_global)):\n",
    "                    subject = subjects_list_global[subject_order]\n",
    "                    metrics_file_path = get_save_path(basic_file_path, gait_or_motion, motion_type, model_name, subject)\n",
    "                    metrics_file_name = os.path.join(metrics_file_path['absolute_path'], 'test_metrics_hmm.csv')\n",
    "                    # 判断文件是否存在\n",
    "                    if not os.path.exists(metrics_file_name):\n",
    "                        print(\"受试者：%s 的文件: %s， 不存在！\" %(subject, metrics_file_name))\n",
    "                    else:\n",
    "                        # 读取每个受试者的test_metrics\n",
    "                        print(\"读取受试者：%s 的test_metrics_hmm: \" %subject)\n",
    "                        df = pd.read_csv(metrics_file_name, header=0, index_col=0)\n",
    "                        # ignore_index=True参数用于重置索引，以确保索引是连续的\n",
    "                        df1_metrics.extend(df.T.values[:-2, :])\n",
    "                        df2_metrics_mean.append(df.T.values[-2, :])\n",
    "                        df2_metrics_std.append(df.T.values[-1, :])\n",
    "                \n",
    "                printlog(info='当前模型：%s, 保存所有受试者所有测试指标的平均结果' % model_name, time=False, line_break=False)\n",
    "                df1 = pd.DataFrame(df1_metrics, index=range(1, len(df1_metrics) + 1), columns=df.index)\n",
    "                # 计算平均值并添加到DataFrame\n",
    "                mean_row = df1.mean().to_frame().T  # 转换为DataFrame并进行转置\n",
    "                mean_row.index = ['mean']  # 设置索引名称\n",
    "                df1 = pd.concat([df1, mean_row])\n",
    "                # 计算标准差并添加到DataFrame\n",
    "                std_row = df1[:-1].std().to_frame().T  # 转换为DataFrame并进行转置，排除最后一行(mean行)来计算标准差\n",
    "                std_row.index = ['std']  # 设置索引名称\n",
    "                df1 = pd.concat([df1, std_row]).round(3)\n",
    "                # 保存df1  \n",
    "                dfs_save_path = os.path.dirname(metrics_file_path['absolute_path'])\n",
    "                df1_save_name = os.path.join(dfs_save_path, 'all_metrics_averaged_results_hmm.csv')\n",
    "                df1.to_csv(df1_save_name, index=True)\n",
    "                \n",
    "                printlog(info='当前模型：%s, 保存单个受试者测试指标平均的平均结果' % model_name, time=False, line_break=False)\n",
    "                # 保存df2\n",
    "                df2_metrics_mean, df2_metrics_std = np.round(np.array(df2_metrics_mean), 3), np.round(np.array(df2_metrics_std), 3)\n",
    "                df2_metrics = np.array([str(df2_metrics_mean[i, j]) +'+'+ str(df2_metrics_std[i, j]) for i in range(df2_metrics_mean.shape[0]) for j in range(df2_metrics_mean.shape[1])])\n",
    "                df2_metrics = df2_metrics.reshape(df2_metrics_mean.shape)\n",
    "                df2 = pd.DataFrame(df2_metrics, index=['Sub'+i for i in subjects_list_global], columns=df.index)\n",
    "                # 计算平均值并添加到DataFrame\n",
    "                mean_row = np.round(np.mean(df2_metrics_mean, axis=0), 3)\n",
    "                std_row = np.round(np.std(df2_metrics_mean, axis=0), 3)\n",
    "                df2.loc['mean'] = mean_row\n",
    "                df2.loc['std'] = std_row\n",
    "                df2_save_name = os.path.join(dfs_save_path, 'alone_subject_averaged_results_hmm.csv')\n",
    "                df2.to_csv(df2_save_name, index=True)\n",
    "\"\"\"       "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. 以下为测试KNN构图方式的代码"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## 5. 以下为测试KNNRatio的代码\n",
    "# pip install torch-cluster\n",
    "\"\"\"\n",
    "total_exp_time = 5\n",
    "network_branch = 1\n",
    "gait_or_motion = 'gait' # 'gait', 'motion'\n",
    "motion_type = 'WAK' #'WAK', 'UPS', 'DNS'\n",
    "conv_type = 'Conv'\n",
    "edge_gen_mode = 'KNN'\n",
    "settings_dict = {'total_exp_time': total_exp_time, 'network_branch': network_branch}\n",
    "params = {'max_esr_ratio': 0.3, 'trg_edge_connect_mode': 'node_random', 'node_embedding': False, \n",
    "          'pcc_kgnn_gen_mode': 'train_set', 'pcc_act_thr': 0.5, 'kgnn_ratio': 0.5, 'kgnn_act_thr': 0.5,\n",
    "          'awmf_act_thr': 0.5, 'AWMF_type': ['PSK', 'TRG', 'PCC', 'KNN']}\n",
    "\n",
    "# pcc_kgnn_gen_modes = ['batch_cnn_feature', 'batch_train_data', 'train_set']\n",
    "pcc_kgnn_gen_modes = ['train_set']\n",
    "kgnn_ratios = [0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "gnn_modes = ['TransformerConv','LEConv']\n",
    "callbacks['criterion']['loss_type'] = 'AttenuationWeightedCE'\n",
    "\n",
    "for pcc_kgnn_gen_mode in pcc_kgnn_gen_modes:\n",
    "    params['pcc_kgnn_gen_mode'] = pcc_kgnn_gen_mode\n",
    "    \n",
    "    for gnn_mode in gnn_modes:\n",
    "        if pcc_kgnn_gen_mode == 'train_set':\n",
    "            kgnn_act_thrs = [0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "            if gnn_mode == 'LEConv':\n",
    "                edge_weight_mode = 'learnable' \n",
    "        else:\n",
    "            edge_weight_mode = 'default'\n",
    "            kgnn_act_thrs = ['default_weight']\n",
    "            \n",
    "        for kgnn_act_thr in kgnn_act_thrs:\n",
    "            params['kgnn_act_thr'] = kgnn_act_thr\n",
    "            \n",
    "            for kgnn_ratio in kgnn_ratios:\n",
    "                params['kgnn_ratio'] = kgnn_ratio\n",
    "                params['pcc_kgnn_adjs'] = None\n",
    "                \n",
    "                model = GeneralGNNs(network_branch, gnn_mode, edge_gen_mode, edge_weight_mode, graph_fusion_mode, readout_mode,\n",
    "                             conv_type, node_amount, gait_or_motion, motion_type, psk_path, params)\n",
    "                model_name = model.get_model_name()\n",
    "                printlog(info=get_print_info(gait_or_motion, motion_type, subjects_list_global), time=False, line_break=False)\n",
    "                basic_save_path = os.path.join(os.path.dirname(os.getcwd()) , 'results', 'Intra-Subject', '8-GNNs-KNNTest', pcc_kgnn_gen_mode,\n",
    "                                               str(kgnn_act_thr), str(kgnn_ratio))\n",
    "                ## 开始训练和测试\n",
    "                for subject_order in range(len(subjects_list_global)):\n",
    "                    subject = subjects_list_global[subject_order]\n",
    "                    file_name, class_weights, encoded_label_name, raw_label_type, true_labels  = get_fileName_weights(file_path, gait_or_motion, motion_type, subject, subjects_list_global)\n",
    "                    save_path = get_save_path(basic_save_path, gait_or_motion, motion_type, model_name, subject)\n",
    "                    print('保存结果的绝对路径： ', save_path['absolute_path'])\n",
    "                    print('保存结果的相对路径： ', save_path['relative_path'])\n",
    "                    \n",
    "                    callbacks['weights'] = class_weights\n",
    "                    train_test_utils['confusion_matrix']['params']['label_type'] = raw_label_type\n",
    "                    \n",
    "                    for exp_tim in range(total_exp_time):\n",
    "                        clear()\n",
    "                        current_exp_time = exp_tim + 1\n",
    "                        settings_dict['current_exp_time'] = current_exp_time\n",
    "                        printlog(info='当前模型：%s'% model_name, time=True, line_break=False)\n",
    "                        print('edge生成方式: %s, pcc_kgnn_gen_mode: %s'% (edge_gen_mode, params['pcc_kgnn_gen_mode']))\n",
    "                        print('kgnn_act_thr: %s, kgnn_ratio: %.2f'% (str(params['kgnn_act_thr']), params['kgnn_ratio']))\n",
    "                        \n",
    "                        printlog(info='当前受试者编号：%s' % subject, time=True, line_break=False)\n",
    "                        printlog(info='当前实验次数：%d / %d' % (current_exp_time, total_exp_time), time=True, line_break=False)\n",
    "                        train_loader, valid_loader, test_loader = get_intra_dataloaders(file_name, data_list, feature_list, encoded_label_name, total_exp_time,gait_or_motion, current_exp_time, train_batch, test_batch, valid_batch, train_test_utils['hmm_tools']['gait_dataset_divide_mode'])\n",
    "                        if gait_or_motion == 'gait':\n",
    "                            print('步态数据集划分方式： ', train_test_utils['hmm_tools']['gait_dataset_divide_mode'])\n",
    "                        print('Sample size of train set, valid set and test set are: ', len(train_loader.dataset), len(valid_loader.dataset), len(test_loader.dataset))\n",
    "                        if edge_gen_mode in ['PCC', 'KNN'] and params['pcc_kgnn_gen_mode'] == 'train_set':\n",
    "                            params['pcc_kgnn_adjs'] = get_pcc_knn_adj_from_dataloader(train_loader, params, edge_gen_mode)\n",
    "                        elif edge_gen_mode == 'AWMF' and ('PCC' in params['AWMF_type'] or 'KNN' in params['AWMF_type']):\n",
    "                            params['pcc_kgnn_adjs'] = get_pcc_knn_adj_from_dataloader(train_loader, params, edge_gen_mode)\n",
    "                        else:\n",
    "                            params['pcc_kgnn_adjs'] = None\n",
    "                        model = GeneralGNNs(network_branch, gnn_mode, edge_gen_mode, edge_weight_mode, graph_fusion_mode, readout_mode,\n",
    "                             conv_type, node_amount, gait_or_motion, motion_type, psk_path, params)\n",
    "                        model.double()\n",
    "                        model.to(device=device)\n",
    "                        train_test_intra_model(settings_dict, model, train_loader, valid_loader, test_loader, device, save_path, callbacks, train_test_utils, true_labels)\n",
    "                        \n",
    "                # 当一个模型针对所有受试者全部训练测试后， 计算保存所有受试者的平均结果\n",
    "                # 新增一个记录所有受试者的所有测试结果的df1\n",
    "                df1_metrics = []\n",
    "                df2_metrics_mean = []\n",
    "                df2_metrics_std = []\n",
    "                printlog(info='当前模型：%s' % model_name, time=True, line_break=True)\n",
    "                basic_file_path = os.path.join(os.path.dirname(os.getcwd()) , 'results', 'Intra-Subject', '8-GNNs-KNNTest', pcc_kgnn_gen_mode,\n",
    "                                               str(kgnn_act_thr), str(kgnn_ratio))\n",
    "                \n",
    "                for subject_order in range(len(subjects_list_global)):\n",
    "                    subject = subjects_list_global[subject_order]\n",
    "                    metrics_file_path = get_save_path(basic_file_path, gait_or_motion, motion_type, model_name, subject)\n",
    "                    metrics_file_name = os.path.join(metrics_file_path['absolute_path'], 'test_metrics.csv')\n",
    "                    # 判断文件是否存在\n",
    "                    if not os.path.exists(metrics_file_name):\n",
    "                        print(\"受试者：%s 的文件: %s， 不存在！\" %(subject, metrics_file_name))\n",
    "                    else:\n",
    "                        # 读取每个受试者的test_metrics\n",
    "                        print(\"读取受试者：%s 的test_metrics: \" %subject)\n",
    "                        df = pd.read_csv(metrics_file_name, header=0, index_col=0)\n",
    "                        # ignore_index=True参数用于重置索引，以确保索引是连续的\n",
    "                        df1_metrics.extend(df.T.values[:-2, :])\n",
    "                        df2_metrics_mean.append(df.T.values[-2, :])\n",
    "                        df2_metrics_std.append(df.T.values[-1, :])\n",
    "                    \n",
    "                printlog(info='当前模型：%s, 保存所有受试者所有测试指标的平均结果' % model_name, time=False, line_break=False)\n",
    "                df1 = pd.DataFrame(df1_metrics, index=range(1, len(df1_metrics) + 1), columns=df.index)\n",
    "                # 计算平均值并添加到DataFrame\n",
    "                mean_row = df1.mean().to_frame().T  # 转换为DataFrame并进行转置\n",
    "                mean_row.index = ['mean']  # 设置索引名称\n",
    "                df1 = pd.concat([df1, mean_row])\n",
    "                # 计算标准差并添加到DataFrame\n",
    "                std_row = df1[:-1].std().to_frame().T  # 转换为DataFrame并进行转置，排除最后一行(mean行)来计算标准差\n",
    "                std_row.index = ['std']  # 设置索引名称\n",
    "                df1 = pd.concat([df1, std_row]).round(3)\n",
    "                # 保存df1  \n",
    "                dfs_save_path = os.path.dirname(metrics_file_path['absolute_path'])\n",
    "                df1_save_name = os.path.join(dfs_save_path, 'all_metrics_averaged_results.csv')\n",
    "                df1.to_csv(df1_save_name, index=True)\n",
    "                \n",
    "                printlog(info='当前模型：%s, 保存单个受试者测试指标平均的平均结果' % model_name, time=False, line_break=False)\n",
    "                # 保存df2\n",
    "                df2_metrics_mean, df2_metrics_std = np.round(np.array(df2_metrics_mean), 3), np.round(np.array(df2_metrics_std), 3)\n",
    "                df2_metrics = np.array([str(df2_metrics_mean[i, j]) +'+'+ str(df2_metrics_std[i, j]) for i in range(df2_metrics_mean.shape[0]) for j in range(df2_metrics_mean.shape[1])])\n",
    "                df2_metrics = df2_metrics.reshape(df2_metrics_mean.shape)\n",
    "                df2 = pd.DataFrame(df2_metrics, index=['Sub'+i for i in subjects_list_global], columns=df.index)\n",
    "                # 计算平均值并添加到DataFrame\n",
    "                mean_row = np.round(np.mean(df2_metrics_mean, axis=0), 3)\n",
    "                std_row = np.round(np.std(df2_metrics_mean, axis=0), 3)\n",
    "                df2.loc['mean'] = mean_row\n",
    "                df2.loc['std'] = std_row\n",
    "                df2_save_name = os.path.join(dfs_save_path, 'alone_subject_averaged_results.csv')\n",
    "                df2.to_csv(df2_save_name, index=True)\n",
    "                \n",
    "                if gait_or_motion == 'gait' and train_test_utils['hmm_tools']['use_hmm']:\n",
    "                    ## test_metrics——hmm.csv处理\n",
    "                    # 新增一个记录所有受试者的所有测试结果的df1\n",
    "                    df1_metrics = []\n",
    "                    df2_metrics_mean = []\n",
    "                    df2_metrics_std = []\n",
    "                    for subject_order in range(len(subjects_list_global)):\n",
    "                        subject = subjects_list_global[subject_order]\n",
    "                        metrics_file_path = get_save_path(basic_file_path, gait_or_motion, motion_type, model_name, subject)\n",
    "                        metrics_file_name = os.path.join(metrics_file_path['absolute_path'], 'test_metrics_hmm.csv')\n",
    "                        # 判断文件是否存在\n",
    "                        if not os.path.exists(metrics_file_name):\n",
    "                            print(\"受试者：%s 的文件: %s， 不存在！\" %(subject, metrics_file_name))\n",
    "                        else:\n",
    "                            # 读取每个受试者的test_metrics\n",
    "                            print(\"读取受试者：%s 的test_metrics_hmm: \" %subject)\n",
    "                            df = pd.read_csv(metrics_file_name, header=0, index_col=0)\n",
    "                            # ignore_index=True参数用于重置索引，以确保索引是连续的\n",
    "                            df1_metrics.extend(df.T.values[:-2, :])\n",
    "                            df2_metrics_mean.append(df.T.values[-2, :])\n",
    "                            df2_metrics_std.append(df.T.values[-1, :])\n",
    "                    \n",
    "                    printlog(info='当前模型：%s, 保存所有受试者所有测试指标的平均结果' % model_name, time=False, line_break=False)\n",
    "                    df1 = pd.DataFrame(df1_metrics, index=range(1, len(df1_metrics) + 1), columns=df.index)\n",
    "                    # 计算平均值并添加到DataFrame\n",
    "                    mean_row = df1.mean().to_frame().T  # 转换为DataFrame并进行转置\n",
    "                    mean_row.index = ['mean']  # 设置索引名称\n",
    "                    df1 = pd.concat([df1, mean_row])\n",
    "                    # 计算标准差并添加到DataFrame\n",
    "                    std_row = df1[:-1].std().to_frame().T  # 转换为DataFrame并进行转置，排除最后一行(mean行)来计算标准差\n",
    "                    std_row.index = ['std']  # 设置索引名称\n",
    "                    df1 = pd.concat([df1, std_row]).round(3)\n",
    "                    # 保存df1  \n",
    "                    dfs_save_path = os.path.dirname(metrics_file_path['absolute_path'])\n",
    "                    df1_save_name = os.path.join(dfs_save_path, 'all_metrics_averaged_results_hmm.csv')\n",
    "                    df1.to_csv(df1_save_name, index=True)\n",
    "                    \n",
    "                    printlog(info='当前模型：%s, 保存单个受试者测试指标平均的平均结果' % model_name, time=False, line_break=False)\n",
    "                    # 保存df2\n",
    "                    df2_metrics_mean, df2_metrics_std = np.round(np.array(df2_metrics_mean), 3), np.round(np.array(df2_metrics_std), 3)\n",
    "                    df2_metrics = np.array([str(df2_metrics_mean[i, j]) +'+'+ str(df2_metrics_std[i, j]) for i in range(df2_metrics_mean.shape[0]) for j in range(df2_metrics_mean.shape[1])])\n",
    "                    df2_metrics = df2_metrics.reshape(df2_metrics_mean.shape)\n",
    "                    df2 = pd.DataFrame(df2_metrics, index=['Sub'+i for i in subjects_list_global], columns=df.index)\n",
    "                    # 计算平均值并添加到DataFrame\n",
    "                    mean_row = np.round(np.mean(df2_metrics_mean, axis=0), 3)\n",
    "                    std_row = np.round(np.std(df2_metrics_mean, axis=0), 3)\n",
    "                    df2.loc['mean'] = mean_row\n",
    "                    df2.loc['std'] = std_row\n",
    "                    df2_save_name = os.path.join(dfs_save_path, 'alone_subject_averaged_results_hmm.csv')\n",
    "                    df2.to_csv(df2_save_name, index=True)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. 以下为测试AWMF构图方式的代码"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## 6. 以下为测试AWMF构图的代码\n",
    "\"\"\"\n",
    "# 1) 固定参数\n",
    "total_exp_time = 5\n",
    "network_branch = 1\n",
    "gait_or_motion = 'gait' # 'gait', 'motion'\n",
    "motion_type = 'WAK' #'WAK', 'UPS', 'DNS'\n",
    "conv_type = 'Conv'\n",
    "edge_gen_mode = 'AWMF'\n",
    "gnn_modes = ['LEConv', 'GATv2Conv', 'TransformerConv']\n",
    "settings_dict = {'total_exp_time': total_exp_time, 'network_branch': network_branch}\n",
    "params = {'max_esr_ratio': 0.2, 'trg_edge_connect_mode': 'node_random', 'node_embedding': False, \n",
    "          'pcc_kgnn_gen_mode': 'train_set', 'pcc_act_thr': 0.5, 'kgnn_ratio': 0.3, 'kgnn_act_thr': 0.3,\n",
    "          'awmf_act_thr': 0.5, 'AWMF_type': ['TRG', 'PSK', 'PCC', 'KNN']}\n",
    "callbacks['criterion']['loss_type'] = 'AttenuationWeightedCE'\n",
    "# 2) 调节参数\n",
    "graph_fusion_modes = ['default', 'learnable']\n",
    "# AWMF_types = [['TRG', 'PSK'], ['TRG', 'PCC'], ['TRG','KNN'], ['PCC', 'PSK'], ['PCC', 'KNN'], ['PSK','KNN'], \n",
    "#               ['TRG', 'PSK', 'PCC'], ['TRG', 'PSK', 'KNN'], ['TRG', 'PCC', 'KNN'], ['PSK', 'PCC', 'KNN'], \n",
    "#               ['TRG', 'PSK', 'PCC', 'KNN']]\n",
    "\n",
    "AWMF_types = [['TRG', 'PSK'], ['TRG','KNN'], ['PSK','KNN'], \n",
    "              ['TRG', 'PSK', 'PCC'], ['TRG', 'PSK', 'KNN']]\n",
    "\n",
    "for gnn_mode in gnn_modes:\n",
    "    if gnn_mode == 'LEConv':\n",
    "        edge_weight_modes = ['default', 'learnable'] # 这里AWMF的edge_weight和其他图拓扑的可训练的边权不同，只是一个融合后计算出的系数\n",
    "    elif gnn_mode in ['GATv2Conv', 'TransformerConv']:\n",
    "        edge_weight_modes = ['default']\n",
    "    else: \n",
    "        raise ValueError('gnn_mode only support \"LEConv\", \"GATv2Conv\", \"TransformerConv\" ')\n",
    "    \n",
    "    for graph_fusion_mode in graph_fusion_modes: \n",
    "        for edge_weight_mode in edge_weight_modes:\n",
    "            for index in range(len(AWMF_types)):\n",
    "                AWMF_type = AWMF_types[index]\n",
    "                AWMF_type_str = AWMF_type[0]\n",
    "                for k in range(1, len(AWMF_type)):\n",
    "                    AWMF_type_str = AWMF_type_str + '-' + AWMF_type[k]\n",
    "                params['AWMF_type'] = AWMF_type\n",
    "                awmf_act_thrs = [i / len(AWMF_type) for i in range(1, len(AWMF_type))]\n",
    "                \n",
    "                for awmf_act_thr in awmf_act_thrs:\n",
    "                    params['pcc_kgnn_adjs'] = None\n",
    "                    params['awmf_act_thr'] = float(awmf_act_thr - 0.01)\n",
    "                    \n",
    "                    model = GeneralGNNs(network_branch, gnn_mode, edge_gen_mode, edge_weight_mode, graph_fusion_mode, readout_mode,\n",
    "                                 conv_type, node_amount, gait_or_motion, motion_type, psk_path, params)\n",
    "                    model_name = model.get_model_name()\n",
    "                    printlog(info=get_print_info(gait_or_motion, motion_type, subjects_list_global), time=False, line_break=False)\n",
    "                    basic_save_path = os.path.join(os.path.dirname(os.getcwd()) , 'results', 'Intra-Subject', '9-GNNs-AWMFTest', graph_fusion_mode, edge_weight_mode, AWMF_type_str, str(awmf_act_thr))\n",
    "                    ## 开始训练和测试\n",
    "                    for subject_order in range(len(subjects_list_global)):\n",
    "                        subject = subjects_list_global[subject_order]\n",
    "                        file_name, class_weights, encoded_label_name, raw_label_type, true_labels  = get_fileName_weights(file_path, gait_or_motion, motion_type, subject, subjects_list_global)\n",
    "                        save_path = get_save_path(basic_save_path, gait_or_motion, motion_type, model_name, subject)\n",
    "                        print('保存结果的绝对路径： ', save_path['absolute_path'])\n",
    "                        print('保存结果的相对路径： ', save_path['relative_path'])\n",
    "                        \n",
    "                        callbacks['weights'] = class_weights\n",
    "                        train_test_utils['confusion_matrix']['params']['label_type'] = raw_label_type\n",
    "                        \n",
    "                        for exp_tim in range(total_exp_time):\n",
    "                            clear()\n",
    "                            current_exp_time = exp_tim + 1\n",
    "                            settings_dict['current_exp_time'] = current_exp_time\n",
    "                            printlog(info='当前模型：%s'% model_name, time=True, line_break=False)\n",
    "                            print('edg_gen_mode: %s, graph_fusion_mode: %s, edge_weight_mode: %s '% (edge_gen_mode, graph_fusion_mode, edge_weight_mode))\n",
    "                            print('AWMF_type: %s, awmf_act_thr: %.4f'% (AWMF_type_str, awmf_act_thr))\n",
    "                            \n",
    "                            printlog(info='当前受试者编号：%s' % subject, time=True, line_break=False)\n",
    "                            printlog(info='当前实验次数：%d / %d' % (current_exp_time, total_exp_time), time=True, line_break=False)\n",
    "                            train_loader, valid_loader, test_loader = get_intra_dataloaders(file_name, data_list, feature_list, encoded_label_name, total_exp_time,gait_or_motion, current_exp_time, train_batch, test_batch, valid_batch, train_test_utils['hmm_tools']['gait_dataset_divide_mode'])\n",
    "                            if gait_or_motion == 'gait':\n",
    "                                print('步态数据集划分方式： ', train_test_utils['hmm_tools']['gait_dataset_divide_mode'])\n",
    "                            print('Sample size of train set, valid set and test set are: ', len(train_loader.dataset), len(valid_loader.dataset), len(test_loader.dataset))\n",
    "                            if edge_gen_mode in ['PCC', 'KNN'] and params['pcc_kgnn_gen_mode'] == 'train_set':\n",
    "                                params['pcc_kgnn_adjs'] = get_pcc_knn_adj_from_dataloader(train_loader, params, edge_gen_mode)\n",
    "                            elif edge_gen_mode == 'AWMF' and ('PCC' in params['AWMF_type'] or 'KNN' in params['AWMF_type']):\n",
    "                                params['pcc_kgnn_adjs'] = get_pcc_knn_adj_from_dataloader(train_loader, params, edge_gen_mode)\n",
    "                            else:\n",
    "                                params['pcc_kgnn_adjs'] = None\n",
    "                            model = GeneralGNNs(network_branch, gnn_mode, edge_gen_mode, edge_weight_mode, graph_fusion_mode, readout_mode,\n",
    "                                 conv_type, node_amount, gait_or_motion, motion_type, psk_path, params)\n",
    "                            model.double()\n",
    "                            model.to(device=device)\n",
    "                            train_test_intra_model(settings_dict, model, train_loader, valid_loader, test_loader, device, save_path, callbacks, train_test_utils, true_labels)\n",
    "                            \n",
    "                    # 当一个模型针对所有受试者全部训练测试后， 计算保存所有受试者的平均结果\n",
    "                    # 新增一个记录所有受试者的所有测试结果的df1\n",
    "                    df1_metrics = []\n",
    "                    df2_metrics_mean = []\n",
    "                    df2_metrics_std = []\n",
    "                    printlog(info='当前模型：%s' % model_name, time=True, line_break=True)\n",
    "                    basic_file_path = os.path.join(os.path.dirname(os.getcwd()) , 'results', 'Intra-Subject', '9-GNNs-AWMFTest', graph_fusion_mode, edge_weight_mode, AWMF_type_str, str(awmf_act_thr))\n",
    "                    \n",
    "                    for subject_order in range(len(subjects_list_global)):\n",
    "                        subject = subjects_list_global[subject_order]\n",
    "                        metrics_file_path = get_save_path(basic_file_path, gait_or_motion, motion_type, model_name, subject)\n",
    "                        metrics_file_name = os.path.join(metrics_file_path['absolute_path'], 'test_metrics.csv')\n",
    "                        # 判断文件是否存在\n",
    "                        if not os.path.exists(metrics_file_name):\n",
    "                            print(\"受试者：%s 的文件: %s， 不存在！\" %(subject, metrics_file_name))\n",
    "                        else:\n",
    "                            # 读取每个受试者的test_metrics\n",
    "                            print(\"读取受试者：%s 的test_metrics: \" %subject)\n",
    "                            df = pd.read_csv(metrics_file_name, header=0, index_col=0)\n",
    "                            # ignore_index=True参数用于重置索引，以确保索引是连续的\n",
    "                            df1_metrics.extend(df.T.values[:-2, :])\n",
    "                            df2_metrics_mean.append(df.T.values[-2, :])\n",
    "                            df2_metrics_std.append(df.T.values[-1, :])\n",
    "                        \n",
    "                    printlog(info='当前模型：%s, 保存所有受试者所有测试指标的平均结果' % model_name, time=False, line_break=False)\n",
    "                    df1 = pd.DataFrame(df1_metrics, index=range(1, len(df1_metrics) + 1), columns=df.index)\n",
    "                    # 计算平均值并添加到DataFrame\n",
    "                    mean_row = df1.mean().to_frame().T  # 转换为DataFrame并进行转置\n",
    "                    mean_row.index = ['mean']  # 设置索引名称\n",
    "                    df1 = pd.concat([df1, mean_row])\n",
    "                    # 计算标准差并添加到DataFrame\n",
    "                    std_row = df1[:-1].std().to_frame().T  # 转换为DataFrame并进行转置，排除最后一行(mean行)来计算标准差\n",
    "                    std_row.index = ['std']  # 设置索引名称\n",
    "                    df1 = pd.concat([df1, std_row]).round(3)\n",
    "                    # 保存df1  \n",
    "                    dfs_save_path = os.path.dirname(metrics_file_path['absolute_path'])\n",
    "                    df1_save_name = os.path.join(dfs_save_path, 'all_metrics_averaged_results.csv')\n",
    "                    df1.to_csv(df1_save_name, index=True)\n",
    "                    \n",
    "                    printlog(info='当前模型：%s, 保存单个受试者测试指标平均的平均结果' % model_name, time=False, line_break=False)\n",
    "                    # 保存df2\n",
    "                    df2_metrics_mean, df2_metrics_std = np.round(np.array(df2_metrics_mean), 3), np.round(np.array(df2_metrics_std), 3)\n",
    "                    df2_metrics = np.array([str(df2_metrics_mean[i, j]) +'+'+ str(df2_metrics_std[i, j]) for i in range(df2_metrics_mean.shape[0]) for j in range(df2_metrics_mean.shape[1])])\n",
    "                    df2_metrics = df2_metrics.reshape(df2_metrics_mean.shape)\n",
    "                    df2 = pd.DataFrame(df2_metrics, index=['Sub'+i for i in subjects_list_global], columns=df.index)\n",
    "                    # 计算平均值并添加到DataFrame\n",
    "                    mean_row = np.round(np.mean(df2_metrics_mean, axis=0), 3)\n",
    "                    std_row = np.round(np.std(df2_metrics_mean, axis=0), 3)\n",
    "                    df2.loc['mean'] = mean_row\n",
    "                    df2.loc['std'] = std_row\n",
    "                    df2_save_name = os.path.join(dfs_save_path, 'alone_subject_averaged_results.csv')\n",
    "                    df2.to_csv(df2_save_name, index=True)\n",
    "                    \n",
    "                    if gait_or_motion == 'gait' and train_test_utils['hmm_tools']['use_hmm']:\n",
    "                        ## test_metrics——hmm.csv处理\n",
    "                        # 新增一个记录所有受试者的所有测试结果的df1\n",
    "                        df1_metrics = []\n",
    "                        df2_metrics_mean = []\n",
    "                        df2_metrics_std = []\n",
    "                        for subject_order in range(len(subjects_list_global)):\n",
    "                            subject = subjects_list_global[subject_order]\n",
    "                            metrics_file_path = get_save_path(basic_file_path, gait_or_motion, motion_type, model_name, subject)\n",
    "                            metrics_file_name = os.path.join(metrics_file_path['absolute_path'], 'test_metrics_hmm.csv')\n",
    "                            # 判断文件是否存在\n",
    "                            if not os.path.exists(metrics_file_name):\n",
    "                                print(\"受试者：%s 的文件: %s， 不存在！\" %(subject, metrics_file_name))\n",
    "                            else:\n",
    "                                # 读取每个受试者的test_metrics\n",
    "                                print(\"读取受试者：%s 的test_metrics_hmm: \" %subject)\n",
    "                                df = pd.read_csv(metrics_file_name, header=0, index_col=0)\n",
    "                                # ignore_index=True参数用于重置索引，以确保索引是连续的\n",
    "                                df1_metrics.extend(df.T.values[:-2, :])\n",
    "                                df2_metrics_mean.append(df.T.values[-2, :])\n",
    "                                df2_metrics_std.append(df.T.values[-1, :])\n",
    "                        \n",
    "                        printlog(info='当前模型：%s, 保存所有受试者所有测试指标的平均结果' % model_name, time=False, line_break=False)\n",
    "                        df1 = pd.DataFrame(df1_metrics, index=range(1, len(df1_metrics) + 1), columns=df.index)\n",
    "                        # 计算平均值并添加到DataFrame\n",
    "                        mean_row = df1.mean().to_frame().T  # 转换为DataFrame并进行转置\n",
    "                        mean_row.index = ['mean']  # 设置索引名称\n",
    "                        df1 = pd.concat([df1, mean_row])\n",
    "                        # 计算标准差并添加到DataFrame\n",
    "                        std_row = df1[:-1].std().to_frame().T  # 转换为DataFrame并进行转置，排除最后一行(mean行)来计算标准差\n",
    "                        std_row.index = ['std']  # 设置索引名称\n",
    "                        df1 = pd.concat([df1, std_row]).round(3)\n",
    "                        # 保存df1  \n",
    "                        dfs_save_path = os.path.dirname(metrics_file_path['absolute_path'])\n",
    "                        df1_save_name = os.path.join(dfs_save_path, 'all_metrics_averaged_results_hmm.csv')\n",
    "                        df1.to_csv(df1_save_name, index=True)\n",
    "                        \n",
    "                        printlog(info='当前模型：%s, 保存单个受试者测试指标平均的平均结果' % model_name, time=False, line_break=False)\n",
    "                        # 保存df2\n",
    "                        df2_metrics_mean, df2_metrics_std = np.round(np.array(df2_metrics_mean), 3), np.round(np.array(df2_metrics_std), 3)\n",
    "                        df2_metrics = np.array([str(df2_metrics_mean[i, j]) +'+'+ str(df2_metrics_std[i, j]) for i in range(df2_metrics_mean.shape[0]) for j in range(df2_metrics_mean.shape[1])])\n",
    "                        df2_metrics = df2_metrics.reshape(df2_metrics_mean.shape)\n",
    "                        df2 = pd.DataFrame(df2_metrics, index=['Sub'+i for i in subjects_list_global], columns=df.index)\n",
    "                        # 计算平均值并添加到DataFrame\n",
    "                        mean_row = np.round(np.mean(df2_metrics_mean, axis=0), 3)\n",
    "                        std_row = np.round(np.std(df2_metrics_mean, axis=0), 3)\n",
    "                        df2.loc['mean'] = mean_row\n",
    "                        df2.loc['std'] = std_row\n",
    "                        df2_save_name = os.path.join(dfs_save_path, 'alone_subject_averaged_results_hmm.csv')\n",
    "                        df2.to_csv(df2_save_name, index=True)\n",
    "\"\"\"     "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. 以下为测试KNN和AWMF构图，单双分支的LEConv在不同损失函数中的差异代码"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## 7. 以下为测试KNN和AWMF构图，单双分支的LEConv在不同损失函数中的差异代码\n",
    "\"\"\"\n",
    "gait_or_motion = 'gait' # 'gait', 'motion'\n",
    "motion_type = 'WAK' #'WAK', 'UPS', 'DNS'\n",
    "total_exp_time = 5\n",
    "settings_dict = {'total_exp_time': total_exp_time, 'network_branch': network_branch}\n",
    "params = {'max_esr_ratio': 0.2, 'trg_edge_connect_mode': 'node_random', 'node_embedding': False, \n",
    "          'pcc_kgnn_gen_mode': 'train_set', 'pcc_act_thr': 0.5, 'kgnn_ratio': 0.3, 'kgnn_act_thr': 0.3,\n",
    "          'awmf_act_thr': 1/3, 'AWMF_type': ['TRG', 'PSK', 'KNN']}\n",
    "conv_type = 'Conv' \n",
    "graph_fusion_mode = 'default'\n",
    "gnn_mode = 'LEConv'\n",
    "\n",
    "# 要更改的参数\n",
    "edge_gen_modes = ['KNN', 'AWMF']\n",
    "network_branchs = [1, 2]\n",
    "if gait_or_motion == 'motion':\n",
    "    criterions = ['FL']\n",
    "    params['max_esr_ratio'] = 0.1\n",
    "elif gait_or_motion == 'gait':\n",
    "    criterions = ['CE', 'FL', 'WeightedCE', 'AttenuationWeightedCE']\n",
    "    params['max_esr_ratio'] = 0.2\n",
    "else:\n",
    "    raise ValueError('gait_or_motion must be \"gait\" or \"motion\"')\n",
    "\n",
    "for network_branch in network_branchs:\n",
    "    for edge_gen_mode in edge_gen_modes:\n",
    "        if edge_gen_mode == 'KNN':\n",
    "            edge_weight_mode = 'learnable'\n",
    "        else:\n",
    "            edge_weight_mode = 'default'\n",
    "            \n",
    "        for criterion in criterions:\n",
    "            callbacks['criterion']['loss_type'] = criterion\n",
    "            params['pcc_kgnn_adjs'] = None\n",
    "            params['awmf_act_thr'] = float(params['awmf_act_thr'] - 0.01)\n",
    "            \n",
    "            model = GeneralGNNs(network_branch, gnn_mode, edge_gen_mode, edge_weight_mode, graph_fusion_mode, readout_mode,\n",
    "                         conv_type, node_amount, gait_or_motion, motion_type, psk_path, params)\n",
    "            model_name = model.get_model_name()\n",
    "            printlog(info=get_print_info(gait_or_motion, motion_type, subjects_list_global), time=False, line_break=False)\n",
    "            basic_save_path = os.path.join(os.path.dirname(os.getcwd()) , 'results', 'Intra-Subject', '10-GNNs-LossFunctionTest', criterion)\n",
    "            ## 开始训练和测试\n",
    "            for subject_order in range(len(subjects_list_global)):\n",
    "                subject = subjects_list_global[subject_order]\n",
    "                file_name, class_weights, encoded_label_name, raw_label_type, true_labels  = get_fileName_weights(file_path, gait_or_motion, motion_type, subject, subjects_list_global)\n",
    "                save_path = get_save_path(basic_save_path, gait_or_motion, motion_type, model_name, subject)\n",
    "                print('保存结果的绝对路径： ', save_path['absolute_path'])\n",
    "                print('保存结果的相对路径： ', save_path['relative_path'])\n",
    "                \n",
    "                callbacks['weights'] = class_weights\n",
    "                train_test_utils['confusion_matrix']['params']['label_type'] = raw_label_type\n",
    "                \n",
    "                for exp_tim in range(total_exp_time):\n",
    "                    clear()\n",
    "                    current_exp_time = exp_tim + 1\n",
    "                    settings_dict['current_exp_time'] = current_exp_time\n",
    "                    printlog(info='当前模型：%s'% model_name, time=True, line_break=False)\n",
    "                    print('损失函数: %s'% criterion)\n",
    "                    print('edge_gen_mode: %s, edge_weight_mode: %s'% (edge_gen_mode, edge_weight_mode))\n",
    "                    if edge_gen_mode == 'AWMF':\n",
    "                        print('AWMF-graph_fusion_mode: %s'% graph_fusion_mode)\n",
    "                        \n",
    "                    printlog(info='当前受试者编号：%s' % subject, time=True, line_break=False)\n",
    "                    printlog(info='当前实验次数：%d / %d' % (current_exp_time, total_exp_time), time=True, line_break=False)\n",
    "                    train_loader, valid_loader, test_loader = get_intra_dataloaders(file_name, data_list, feature_list, encoded_label_name, total_exp_time,gait_or_motion, current_exp_time, train_batch, test_batch, valid_batch, train_test_utils['hmm_tools']['gait_dataset_divide_mode'])\n",
    "                    if gait_or_motion == 'gait':\n",
    "                        print('步态数据集划分方式： ', train_test_utils['hmm_tools']['gait_dataset_divide_mode'])\n",
    "                    print('Sample size of train set, valid set and test set are: ', len(train_loader.dataset), len(valid_loader.dataset), len(test_loader.dataset))\n",
    "                    if edge_gen_mode in ['PCC', 'KNN'] and params['pcc_kgnn_gen_mode'] == 'train_set':\n",
    "                        params['pcc_kgnn_adjs'] = get_pcc_knn_adj_from_dataloader(train_loader, params, edge_gen_mode)\n",
    "                    elif edge_gen_mode == 'AWMF' and ('PCC' in params['AWMF_type'] or 'KNN' in params['AWMF_type']):\n",
    "                        params['pcc_kgnn_adjs'] = get_pcc_knn_adj_from_dataloader(train_loader, params, edge_gen_mode)\n",
    "                    else:\n",
    "                        params['pcc_kgnn_adjs'] = None\n",
    "                        \n",
    "                    model = GeneralGNNs(network_branch, gnn_mode, edge_gen_mode, edge_weight_mode, graph_fusion_mode, readout_mode,\n",
    "                         conv_type, node_amount, gait_or_motion, motion_type, psk_path, params)\n",
    "                    model.double()\n",
    "                    model.to(device=device)\n",
    "                    train_test_intra_model(settings_dict, model, train_loader, valid_loader, test_loader, device, save_path, callbacks, train_test_utils, true_labels)\n",
    "                    \n",
    "            # 当一个模型针对所有受试者全部训练测试后， 计算保存所有受试者的平均结果\n",
    "            # 新增一个记录所有受试者的所有测试结果的df1\n",
    "            df1_metrics = []\n",
    "            df2_metrics_mean = []\n",
    "            df2_metrics_std = []\n",
    "            printlog(info='当前模型：%s' % model_name, time=True, line_break=True)\n",
    "            basic_file_path = os.path.join(os.path.dirname(os.getcwd()) , 'results', 'Intra-Subject', '10-GNNs-LossFunctionTest',criterion)\n",
    "            \n",
    "            for subject_order in range(len(subjects_list_global)):\n",
    "                subject = subjects_list_global[subject_order]\n",
    "                metrics_file_path = get_save_path(basic_file_path, gait_or_motion, motion_type, model_name, subject)\n",
    "                metrics_file_name = os.path.join(metrics_file_path['absolute_path'], 'test_metrics.csv')\n",
    "                # 判断文件是否存在\n",
    "                if not os.path.exists(metrics_file_name):\n",
    "                    print(\"受试者：%s 的文件: %s， 不存在！\" %(subject, metrics_file_name))\n",
    "                else:\n",
    "                    # 读取每个受试者的test_metrics\n",
    "                    print(\"读取受试者：%s 的test_metrics: \" %subject)\n",
    "                    df = pd.read_csv(metrics_file_name, header=0, index_col=0)\n",
    "                    # ignore_index=True参数用于重置索引，以确保索引是连续的\n",
    "                    df1_metrics.extend(df.T.values[:-2, :])\n",
    "                    df2_metrics_mean.append(df.T.values[-2, :])\n",
    "                    df2_metrics_std.append(df.T.values[-1, :])\n",
    "                \n",
    "            printlog(info='当前模型：%s, 保存所有受试者所有测试指标的平均结果' % model_name, time=False, line_break=False)\n",
    "            df1 = pd.DataFrame(df1_metrics, index=range(1, len(df1_metrics) + 1), columns=df.index)\n",
    "            # 计算平均值并添加到DataFrame\n",
    "            mean_row = df1.mean().to_frame().T  # 转换为DataFrame并进行转置\n",
    "            mean_row.index = ['mean']  # 设置索引名称\n",
    "            df1 = pd.concat([df1, mean_row])\n",
    "            # 计算标准差并添加到DataFrame\n",
    "            std_row = df1[:-1].std().to_frame().T  # 转换为DataFrame并进行转置，排除最后一行(mean行)来计算标准差\n",
    "            std_row.index = ['std']  # 设置索引名称\n",
    "            df1 = pd.concat([df1, std_row]).round(3)\n",
    "            # 保存df1  \n",
    "            dfs_save_path = os.path.dirname(metrics_file_path['absolute_path'])\n",
    "            df1_save_name = os.path.join(dfs_save_path, 'all_metrics_averaged_results.csv')\n",
    "            df1.to_csv(df1_save_name, index=True)\n",
    "            \n",
    "            printlog(info='当前模型：%s, 保存单个受试者测试指标平均的平均结果' % model_name, time=False, line_break=False)\n",
    "            # 保存df2\n",
    "            df2_metrics_mean, df2_metrics_std = np.round(np.array(df2_metrics_mean), 3), np.round(np.array(df2_metrics_std), 3)\n",
    "            df2_metrics = np.array([str(df2_metrics_mean[i, j]) +'+'+ str(df2_metrics_std[i, j]) for i in range(df2_metrics_mean.shape[0]) for j in range(df2_metrics_mean.shape[1])])\n",
    "            df2_metrics = df2_metrics.reshape(df2_metrics_mean.shape)\n",
    "            df2 = pd.DataFrame(df2_metrics, index=['Sub'+i for i in subjects_list_global], columns=df.index)\n",
    "            # 计算平均值并添加到DataFrame\n",
    "            mean_row = np.round(np.mean(df2_metrics_mean, axis=0), 3)\n",
    "            std_row = np.round(np.std(df2_metrics_mean, axis=0), 3)\n",
    "            df2.loc['mean'] = mean_row\n",
    "            df2.loc['std'] = std_row\n",
    "            df2_save_name = os.path.join(dfs_save_path, 'alone_subject_averaged_results.csv')\n",
    "            df2.to_csv(df2_save_name, index=True)\n",
    "            \n",
    "            if gait_or_motion == 'gait' and train_test_utils['hmm_tools']['use_hmm']:\n",
    "                ## test_metrics——hmm.csv处理\n",
    "                # 新增一个记录所有受试者的所有测试结果的df1\n",
    "                df1_metrics = []\n",
    "                df2_metrics_mean = []\n",
    "                df2_metrics_std = []\n",
    "                for subject_order in range(len(subjects_list_global)):\n",
    "                    subject = subjects_list_global[subject_order]\n",
    "                    metrics_file_path = get_save_path(basic_file_path, gait_or_motion, motion_type, model_name, subject)\n",
    "                    metrics_file_name = os.path.join(metrics_file_path['absolute_path'], 'test_metrics_hmm.csv')\n",
    "                    # 判断文件是否存在\n",
    "                    if not os.path.exists(metrics_file_name):\n",
    "                        print(\"受试者：%s 的文件: %s， 不存在！\" %(subject, metrics_file_name))\n",
    "                    else:\n",
    "                        # 读取每个受试者的test_metrics\n",
    "                        print(\"读取受试者：%s 的test_metrics_hmm: \" %subject)\n",
    "                        df = pd.read_csv(metrics_file_name, header=0, index_col=0)\n",
    "                        # ignore_index=True参数用于重置索引，以确保索引是连续的\n",
    "                        df1_metrics.extend(df.T.values[:-2, :])\n",
    "                        df2_metrics_mean.append(df.T.values[-2, :])\n",
    "                        df2_metrics_std.append(df.T.values[-1, :])\n",
    "                \n",
    "                printlog(info='当前模型：%s, 保存所有受试者所有测试指标的平均结果' % model_name, time=False, line_break=False)\n",
    "                df1 = pd.DataFrame(df1_metrics, index=range(1, len(df1_metrics) + 1), columns=df.index)\n",
    "                # 计算平均值并添加到DataFrame\n",
    "                mean_row = df1.mean().to_frame().T  # 转换为DataFrame并进行转置\n",
    "                mean_row.index = ['mean']  # 设置索引名称\n",
    "                df1 = pd.concat([df1, mean_row])\n",
    "                # 计算标准差并添加到DataFrame\n",
    "                std_row = df1[:-1].std().to_frame().T  # 转换为DataFrame并进行转置，排除最后一行(mean行)来计算标准差\n",
    "                std_row.index = ['std']  # 设置索引名称\n",
    "                df1 = pd.concat([df1, std_row]).round(3)\n",
    "                # 保存df1  \n",
    "                dfs_save_path = os.path.dirname(metrics_file_path['absolute_path'])\n",
    "                df1_save_name = os.path.join(dfs_save_path, 'all_metrics_averaged_results_hmm.csv')\n",
    "                df1.to_csv(df1_save_name, index=True)\n",
    "                \n",
    "                printlog(info='当前模型：%s, 保存单个受试者测试指标平均的平均结果' % model_name, time=False, line_break=False)\n",
    "                # 保存df2\n",
    "                df2_metrics_mean, df2_metrics_std = np.round(np.array(df2_metrics_mean), 3), np.round(np.array(df2_metrics_std), 3)\n",
    "                df2_metrics = np.array([str(df2_metrics_mean[i, j]) +'+'+ str(df2_metrics_std[i, j]) for i in range(df2_metrics_mean.shape[0]) for j in range(df2_metrics_mean.shape[1])])\n",
    "                df2_metrics = df2_metrics.reshape(df2_metrics_mean.shape)\n",
    "                df2 = pd.DataFrame(df2_metrics, index=['Sub'+i for i in subjects_list_global], columns=df.index)\n",
    "                # 计算平均值并添加到DataFrame\n",
    "                mean_row = np.round(np.mean(df2_metrics_mean, axis=0), 3)\n",
    "                std_row = np.round(np.std(df2_metrics_mean, axis=0), 3)\n",
    "                df2.loc['mean'] = mean_row\n",
    "                df2.loc['std'] = std_row\n",
    "                df2_save_name = os.path.join(dfs_save_path, 'alone_subject_averaged_results_hmm.csv')\n",
    "                df2.to_csv(df2_save_name, index=True)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8. 以下为先进方法对比中，测试KNN和AWMF构图，双分支的LEConv在不同损失函数中的差异代码"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## 8. 以下为先进方法对比中，测试KNN和AWMF构图，双分支的LEConv在不同损失函数中的差异代码\n",
    "total_exp_time = 5\n",
    "network_branch = 2\n",
    "settings_dict = {'total_exp_time': total_exp_time, 'network_branch': network_branch}\n",
    "params = {'max_esr_ratio': 0.2, 'trg_edge_connect_mode': 'node_random', 'node_embedding': False, \n",
    "          'pcc_kgnn_gen_mode': 'train_set', 'pcc_act_thr': 0.5, 'kgnn_ratio': 0.3, 'kgnn_act_thr': 0.3,\n",
    "          'awmf_act_thr': 1/3, 'AWMF_type': ['TRG', 'PSK', 'KNN']}\n",
    "conv_type = 'Conv' \n",
    "graph_fusion_mode = 'default'\n",
    "gnn_mode = 'LEConv'\n",
    "\n",
    "# 要更改的参数\n",
    "data_params = {'gait_or_motion': ['motion', 'gait', 'gait', 'gait'],\n",
    "               'motion_type': ['WAK', 'WAK', 'UPS', 'DNS']}\n",
    "edge_gen_modes = ['KNN', 'AWMF']\n",
    "criterions = ['CE', 'FL', 'WeightedCE', 'AttenuationWeightedCE']\n",
    "train_test_utils['confusion_matrix']['get_cm'] = True\n",
    "train_test_utils['tsne_visualization']['get_tsne'] = True\n",
    "\n",
    "for index in range(len(data_params['gait_or_motion'])):\n",
    "    gait_or_motion = data_params['gait_or_motion'][index]\n",
    "    motion_type = data_params['motion_type'][index]\n",
    "    if gait_or_motion == 'motion':\n",
    "        # criterions = ['FL']\n",
    "        params['max_esr_ratio'] = 0.1\n",
    "    elif gait_or_motion == 'gait':\n",
    "        # criterions = ['CE', 'FL', 'WeightedCE', 'AttenuationWeightedCE']\n",
    "        params['max_esr_ratio'] = 0.2\n",
    "    else:\n",
    "        raise ValueError('gait_or_motion must be \"gait\" or \"motion\"')\n",
    "    \n",
    "    for edge_gen_mode in edge_gen_modes:\n",
    "        if edge_gen_mode == 'KNN':\n",
    "            edge_weight_mode = 'learnable'\n",
    "        else:\n",
    "            edge_weight_mode = 'default'\n",
    "            \n",
    "        for criterion in criterions:\n",
    "            callbacks['criterion']['loss_type'] = criterion\n",
    "            params['pcc_kgnn_adjs'] = None\n",
    "            params['awmf_act_thr'] = float(params['awmf_act_thr'] - 0.01)\n",
    "            \n",
    "            model = GeneralGNNs(network_branch, gnn_mode, edge_gen_mode, edge_weight_mode, graph_fusion_mode, readout_mode,\n",
    "                         conv_type, node_amount, gait_or_motion, motion_type, psk_path, params)\n",
    "            model_name = model.get_model_name()\n",
    "            printlog(info=get_print_info(gait_or_motion, motion_type, subjects_list_global), time=False, line_break=False)\n",
    "            basic_save_path = os.path.join(os.path.dirname(os.getcwd()) , 'results', 'Intra-Subject', '11-Start-of-the-artMethodsComparison', criterion)\n",
    "            # basic_save_path = os.path.join(os.path.dirname(os.getcwd()) , 'results', 'Intra-Subject', '11-Start-of-the-artMethodsComparison')\n",
    "            # 开始训练和测试\n",
    "            for subject_order in range(len(subjects_list_global)):\n",
    "                subject = subjects_list_global[subject_order]\n",
    "                file_name, class_weights, encoded_label_name, raw_label_type, true_labels  = get_fileName_weights(file_path, gait_or_motion, motion_type, subject, subjects_list_global)\n",
    "                save_path = get_save_path(basic_save_path, gait_or_motion, motion_type, model_name, subject)\n",
    "                print('保存结果的绝对路径： ', save_path['absolute_path'])\n",
    "                print('保存结果的相对路径： ', save_path['relative_path'])\n",
    "                \n",
    "                callbacks['weights'] = class_weights\n",
    "                train_test_utils['confusion_matrix']['params']['label_type'] = raw_label_type\n",
    "                \n",
    "                for exp_tim in range(total_exp_time):\n",
    "                    clear()\n",
    "                    current_exp_time = exp_tim + 1\n",
    "                    settings_dict['current_exp_time'] = current_exp_time\n",
    "                    printlog(info='当前模型：%s'% model_name, time=True, line_break=False)\n",
    "                    if gait_or_motion == 'motion':\n",
    "                        print('gait_or_motion: %s'% gait_or_motion)\n",
    "                    else:\n",
    "                        print('gait_or_motion: %s, motion_type: %s'% (gait_or_motion, motion_type))\n",
    "                    print('损失函数: %s'% criterion)\n",
    "                    print('edge_gen_mode: %s, edge_weight_mode: %s'% (edge_gen_mode, edge_weight_mode))\n",
    "                    if edge_gen_mode == 'AWMF':\n",
    "                        print('AWMF-graph_fusion_mode: %s'% graph_fusion_mode)\n",
    "                        \n",
    "                    printlog(info='当前受试者编号：%s' % subject, time=True, line_break=False)\n",
    "                    printlog(info='当前实验次数：%d / %d' % (current_exp_time, total_exp_time), time=True, line_break=False)\n",
    "                    train_loader, valid_loader, test_loader = get_intra_dataloaders(file_name, data_list, feature_list, encoded_label_name, total_exp_time,gait_or_motion, current_exp_time, train_batch, test_batch, valid_batch, train_test_utils['hmm_tools']['gait_dataset_divide_mode'])\n",
    "                    if gait_or_motion == 'gait':\n",
    "                        print('步态数据集划分方式： ', train_test_utils['hmm_tools']['gait_dataset_divide_mode'])\n",
    "                    print('Sample size of train set, valid set and test set are: ', len(train_loader.dataset), len(valid_loader.dataset), len(test_loader.dataset))\n",
    "                    if edge_gen_mode in ['PCC', 'KNN'] and params['pcc_kgnn_gen_mode'] == 'train_set':\n",
    "                        params['pcc_kgnn_adjs'] = get_pcc_knn_adj_from_dataloader(train_loader, params, edge_gen_mode)\n",
    "                    elif edge_gen_mode == 'AWMF' and ('PCC' in params['AWMF_type'] or 'KNN' in params['AWMF_type']):\n",
    "                        params['pcc_kgnn_adjs'] = get_pcc_knn_adj_from_dataloader(train_loader, params, edge_gen_mode)\n",
    "                    else:\n",
    "                        params['pcc_kgnn_adjs'] = None\n",
    "                        \n",
    "                    model = GeneralGNNs(network_branch, gnn_mode, edge_gen_mode, edge_weight_mode, graph_fusion_mode, readout_mode,\n",
    "                         conv_type, node_amount, gait_or_motion, motion_type, psk_path, params)\n",
    "                    model.double()\n",
    "                    model.to(device=device)\n",
    "                    train_test_intra_model(settings_dict, model, train_loader, valid_loader, test_loader, device, save_path, callbacks, train_test_utils, true_labels)\n",
    "                    \n",
    "            # 当一个模型针对所有受试者全部训练测试后， 计算保存所有受试者的平均结果\n",
    "            # 新增一个记录所有受试者的所有测试结果的df1\n",
    "            df1_metrics = []\n",
    "            df2_metrics_mean = []\n",
    "            df2_metrics_std = []\n",
    "            printlog(info='当前模型：%s' % model_name, time=True, line_break=True)\n",
    "            basic_file_path = os.path.join(os.path.dirname(os.getcwd()) , 'results', 'Intra-Subject', '11-Start-of-the-artMethodsComparison', criterion)\n",
    "            # basic_file_path = os.path.join(os.path.dirname(os.getcwd()) , 'results', 'Intra-Subject', '11-Start-of-the-artMethodsComparison', criterion)\n",
    "            for subject_order in range(len(subjects_list_global)):\n",
    "                subject = subjects_list_global[subject_order]\n",
    "                metrics_file_path = get_save_path(basic_file_path, gait_or_motion, motion_type, model_name, subject)\n",
    "                metrics_file_name = os.path.join(metrics_file_path['absolute_path'], 'test_metrics.csv')\n",
    "                # 判断文件是否存在\n",
    "                if not os.path.exists(metrics_file_name):\n",
    "                    print(\"受试者：%s 的文件: %s， 不存在！\" %(subject, metrics_file_name))\n",
    "                else:\n",
    "                    # 读取每个受试者的test_metrics\n",
    "                    print(\"读取受试者：%s 的test_metrics: \" %subject)\n",
    "                    df = pd.read_csv(metrics_file_name, header=0, index_col=0)\n",
    "                    # ignore_index=True参数用于重置索引，以确保索引是连续的\n",
    "                    df1_metrics.extend(df.T.values[:-2, :])\n",
    "                    df2_metrics_mean.append(df.T.values[-2, :])\n",
    "                    df2_metrics_std.append(df.T.values[-1, :])\n",
    "                \n",
    "            printlog(info='当前模型：%s, 保存所有受试者所有测试指标的平均结果' % model_name, time=False, line_break=False)\n",
    "            df1 = pd.DataFrame(df1_metrics, index=range(1, len(df1_metrics) + 1), columns=df.index)\n",
    "            # 计算平均值并添加到DataFrame\n",
    "            mean_row = df1.mean().to_frame().T  # 转换为DataFrame并进行转置\n",
    "            mean_row.index = ['mean']  # 设置索引名称\n",
    "            df1 = pd.concat([df1, mean_row])\n",
    "            # 计算标准差并添加到DataFrame\n",
    "            std_row = df1[:-1].std().to_frame().T  # 转换为DataFrame并进行转置，排除最后一行(mean行)来计算标准差\n",
    "            std_row.index = ['std']  # 设置索引名称\n",
    "            df1 = pd.concat([df1, std_row]).round(3)\n",
    "            # 保存df1  \n",
    "            dfs_save_path = os.path.dirname(metrics_file_path['absolute_path'])\n",
    "            df1_save_name = os.path.join(dfs_save_path, 'all_metrics_averaged_results.csv')\n",
    "            df1.to_csv(df1_save_name, index=True)\n",
    "            \n",
    "            printlog(info='当前模型：%s, 保存单个受试者测试指标平均的平均结果' % model_name, time=False, line_break=False)\n",
    "            # 保存df2\n",
    "            df2_metrics_mean, df2_metrics_std = np.round(np.array(df2_metrics_mean), 3), np.round(np.array(df2_metrics_std), 3)\n",
    "            df2_metrics = np.array([str(df2_metrics_mean[i, j]) +'+'+ str(df2_metrics_std[i, j]) for i in range(df2_metrics_mean.shape[0]) for j in range(df2_metrics_mean.shape[1])])\n",
    "            df2_metrics = df2_metrics.reshape(df2_metrics_mean.shape)\n",
    "            df2 = pd.DataFrame(df2_metrics, index=['Sub'+i for i in subjects_list_global], columns=df.index)\n",
    "            # 计算平均值并添加到DataFrame\n",
    "            mean_row = np.round(np.mean(df2_metrics_mean, axis=0), 3)\n",
    "            std_row = np.round(np.std(df2_metrics_mean, axis=0), 3)\n",
    "            df2.loc['mean'] = mean_row\n",
    "            df2.loc['std'] = std_row\n",
    "            df2_save_name = os.path.join(dfs_save_path, 'alone_subject_averaged_results.csv')\n",
    "            df2.to_csv(df2_save_name, index=True)\n",
    "            \n",
    "            if gait_or_motion == 'gait' and train_test_utils['hmm_tools']['use_hmm']:\n",
    "                ## test_metrics——hmm.csv处理\n",
    "                # 新增一个记录所有受试者的所有测试结果的df1\n",
    "                df1_metrics = []\n",
    "                df2_metrics_mean = []\n",
    "                df2_metrics_std = []\n",
    "                for subject_order in range(len(subjects_list_global)):\n",
    "                    subject = subjects_list_global[subject_order]\n",
    "                    metrics_file_path = get_save_path(basic_file_path, gait_or_motion, motion_type, model_name, subject)\n",
    "                    metrics_file_name = os.path.join(metrics_file_path['absolute_path'], 'test_metrics_hmm.csv')\n",
    "                    # 判断文件是否存在\n",
    "                    if not os.path.exists(metrics_file_name):\n",
    "                        print(\"受试者：%s 的文件: %s， 不存在！\" %(subject, metrics_file_name))\n",
    "                    else:\n",
    "                        # 读取每个受试者的test_metrics\n",
    "                        print(\"读取受试者：%s 的test_metrics_hmm: \" %subject)\n",
    "                        df = pd.read_csv(metrics_file_name, header=0, index_col=0)\n",
    "                        # ignore_index=True参数用于重置索引，以确保索引是连续的\n",
    "                        df1_metrics.extend(df.T.values[:-2, :])\n",
    "                        df2_metrics_mean.append(df.T.values[-2, :])\n",
    "                        df2_metrics_std.append(df.T.values[-1, :])\n",
    "                \n",
    "                printlog(info='当前模型：%s, 保存所有受试者所有测试指标的平均结果' % model_name, time=False, line_break=False)\n",
    "                df1 = pd.DataFrame(df1_metrics, index=range(1, len(df1_metrics) + 1), columns=df.index)\n",
    "                # 计算平均值并添加到DataFrame\n",
    "                mean_row = df1.mean().to_frame().T  # 转换为DataFrame并进行转置\n",
    "                mean_row.index = ['mean']  # 设置索引名称\n",
    "                df1 = pd.concat([df1, mean_row])\n",
    "                # 计算标准差并添加到DataFrame\n",
    "                std_row = df1[:-1].std().to_frame().T  # 转换为DataFrame并进行转置，排除最后一行(mean行)来计算标准差\n",
    "                std_row.index = ['std']  # 设置索引名称\n",
    "                df1 = pd.concat([df1, std_row]).round(3)\n",
    "                # 保存df1  \n",
    "                dfs_save_path = os.path.dirname(metrics_file_path['absolute_path'])\n",
    "                df1_save_name = os.path.join(dfs_save_path, 'all_metrics_averaged_results_hmm.csv')\n",
    "                df1.to_csv(df1_save_name, index=True)\n",
    "                \n",
    "                printlog(info='当前模型：%s, 保存单个受试者测试指标平均的平均结果' % model_name, time=False, line_break=False)\n",
    "                # 保存df2\n",
    "                df2_metrics_mean, df2_metrics_std = np.round(np.array(df2_metrics_mean), 3), np.round(np.array(df2_metrics_std), 3)\n",
    "                df2_metrics = np.array([str(df2_metrics_mean[i, j]) +'+'+ str(df2_metrics_std[i, j]) for i in range(df2_metrics_mean.shape[0]) for j in range(df2_metrics_mean.shape[1])])\n",
    "                df2_metrics = df2_metrics.reshape(df2_metrics_mean.shape)\n",
    "                df2 = pd.DataFrame(df2_metrics, index=['Sub'+i for i in subjects_list_global], columns=df.index)\n",
    "                # 计算平均值并添加到DataFrame\n",
    "                mean_row = np.round(np.mean(df2_metrics_mean, axis=0), 3)\n",
    "                std_row = np.round(np.std(df2_metrics_mean, axis=0), 3)\n",
    "                df2.loc['mean'] = mean_row\n",
    "                df2.loc['std'] = std_row\n",
    "                df2_save_name = os.path.join(dfs_save_path, 'alone_subject_averaged_results_hmm.csv')\n",
    "                df2.to_csv(df2_save_name, index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pytorch",
   "language": "python",
   "display_name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
