{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-10-07T17:19:38.001917500Z",
     "start_time": "2023-10-07T17:19:34.304648900Z"
    }
   },
   "outputs": [],
   "source": [
    "# 下面注释掉的适合在非Pycharm 的Juypter Notebook上使用\n",
    "import os\n",
    "# 下面注释掉的适合在非Pycharm 的Juypter Notebook上使用\n",
    "# import sys\n",
    "# path = os.path.join(os.path.dirname(os.getcwd()))\n",
    "# sys.path.append(path) # 将所需要的根目录添加到路径\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# 导入模型可视化和训练过程可视化库\n",
    "from IPython.display import clear_output as clear\n",
    "# 导入模型\n",
    "from models.supervisedModels.CNNs import GeneralCNNs\n",
    "# 导入小工具\n",
    "from utils.common_utils import printlog\n",
    "from trainTest.datasets.dataset_utils import get_fileName_weights, get_save_path, get_intra_dataloaders, get_print_info\n",
    "from trainTest.train.intra_train_cnns import train_test_intra_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-10-07T17:20:01.782567800Z",
     "start_time": "2023-10-07T17:20:01.714974700Z"
    }
   },
   "outputs": [],
   "source": [
    "### 1. 获取文件路径和文件名的设置\n",
    "file_path = os.path.join(os.path.dirname(os.getcwd()) , 'preProcessing', 'trainData')\n",
    "gait_or_motion = 'gait' # 'gait', 'motion'\n",
    "motion_type = 'WAK' #'WAK', 'UPS', 'DNS'\n",
    "subjects_list_global = list(['01', '02', '03', '04', '06', '31', '32', '33', '34', '36'])\n",
    "\n",
    "### 2. 获取dataloaders的设置\n",
    "total_exp_time = 5 \n",
    "train_batch, valid_batch, test_batch = 32, 32, 32\n",
    "data_list = ['sub_emg_sample', 'sub_angle_sample']\n",
    "feature_list = ['sub_emg_features', 'sub_angle_features']\n",
    "\n",
    "### 3. GeneralCNNs模型构建参数设置\n",
    "network_branch = 1\n",
    "\n",
    "### 4. 模型训练和测试的参数设置\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "## 4.1. 迭代次数、初始学习率、优化器、学习率衰减、早停和损失函数的设置\n",
    "# 1)'epoch': int, 最大训练轮数\n",
    "# 2)'initial_lr': 初始学习率，默认0.01\n",
    "# 3)'optimizer': 优化器，默认'Adam'，one of ['Adam', 'RMSprop']\n",
    "# 4)'lr_scheduler': 学习率衰减，scheduler_type: one of ['None', 'StepLR', 'MultiStepLR', 'ExponentialLR', AutoWarmupLR', \n",
    "#                                                   'GradualWarmupLR' ,'ReduceLROnPlateau']\n",
    "# 5)'early_stopping': 早停\n",
    "# 6)'criterion': 'loss_type', 默认'CE'('CrossEntropy')，one of ['CE', 'WeightedCE', 'FL'('FocalLoss'), 'WeightedFL', 'AttenuationWeightedCE', 'AttenuationWeightedFL']\n",
    "#                'modify_type': 'exponent' / 'linear'\n",
    "max_epoch = 100\n",
    "callbacks = {'epoch': max_epoch,\n",
    "             'initial_lr': 0.01,\n",
    "             'optimizer': 'Adam',\n",
    "             'lr_scheduler': {'scheduler_type': 'GradualWarmupLR',\n",
    "                              'params':{\n",
    "                                  'StepLR':{'step_size': int(0.2*max_epoch), 'gamma': np.sqrt(0.1)},\n",
    "                                  'MultiStepLR':{'milestones': [int(0.2*max_epoch), int(0.4*max_epoch), int(0.6*max_epoch), int(0.8*max_epoch)], \n",
    "                                                 'gamma': np.sqrt(0.1)},\n",
    "                                  'ExponentialLR':{'gamma': 0.9},\n",
    "                                  'AutoWarmupLR':{'num_warm': 10},\n",
    "                                  'GradualWarmupLR':{'multiplier': 1, 'total_epoch': 10},\n",
    "                                  'ReduceLROnPlateau':{'mode': 'max', 'factor': np.sqrt(0.1),\n",
    "                                                       'patience': 5, 'verbose': False,\n",
    "                                                       'threshold': 0.0001, 'min_lr': 0.00001},\n",
    "                              }\n",
    "                              },\n",
    "             'early_stopping': {'use_es': True, 'params':{'patience': 20, 'verbose': False, 'delta': 0.0001}},\n",
    "             'criterion': {'loss_type': 'AttenuationWeightedFL', 'params':{'modify_type': 'exponent', 'exponent_factor': 5}}}\n",
    "\n",
    "## 4.2 训练和测试过程中的画图和保存设置\n",
    "# 1) use_tqdm: 为True使用进度条在进度条内打印输出，为False使用hiddenlayer的History打印输出\n",
    "# 2) train_plot: 是否使用hiddenlayer的Canvas为训练过程画图\n",
    "# 3) print_interval: 多少个epoch打印一次输出或更新一次tqdm\n",
    "# 4) model_eval: 使用验证集和测试集评估模型前是否打开model.eval()\n",
    "# 5) test_metrics: list, 整个训练结束后在测试集上评估的指标 ['accuracy', 'precision', 'recall', 'f1', 'specificity', 'npv']\n",
    "# 6) confusion_matrix: dist, 参考'metrics/get_test_metrics函数'. cmap: 'YlGnBu' / 'Blues'\n",
    "#                     'show_type':  {'cm', 'normalized_cm', 'all'}\n",
    "# 7) tsne_visualization: dist, 参考'visualization/tsne函数'\n",
    "#    'show_type':  'train_set' / 'test_set' / 'all', 'feature_type': 'CNN' / 'Linear'\n",
    "# 8）HMM模型for步态识别。步态分类任务的数据集划分方式 gait_dataset_divide_mode： ['random', 'group_fix', 'group_random']\n",
    "train_test_utils = {'use_tqdm': False,\n",
    "                    'train_plot': False,\n",
    "                    'print_interval': 10,\n",
    "                    'model_eval': {'valid': True, 'test': True},\n",
    "                    'test_metrics': ['accuracy', 'precision', 'recall', 'f1', 'specificity', 'npv'],\n",
    "                    'confusion_matrix': {'get_cm': True, 'params':{'show_type': 'all', 'plot': True, 'save_fig': True,\n",
    "                                                                   'save_results': True, 'cmap': 'YlGnBu'}},\n",
    "                    'tsne_visualization': {'get_tsne': True, 'params': {'show_type': 'all', 'feature_type': 'CNN', \n",
    "                                                                        'save_results': True, 'save_fig': True}},\n",
    "                    'hmm_tools': {'gait': gait_or_motion, 'gait_dataset_divide_mode': 'group_random', 'use_hmm': True}\n",
    "                    }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## 1. 以下为测试不同BackBone的代码\n",
    "\"\"\"\n",
    "settings_dict = {'total_exp_time': total_exp_time, 'network_branch': network_branch}\n",
    "conv_types = ['DNN', 'Conv', 'SKConv', 'ResNetV1', 'ResNetV2', 'MobileNetV1', 'MobileNetV2', 'MobileNetV3', 'ResNeSt', 'ShuffleNetV1', 'ShuffleNetV2']\n",
    "\n",
    "for conv_type in conv_types:\n",
    "    model = GeneralCNNs(network_branch, gait_or_motion, motion_type, conv_type=conv_type)\n",
    "    model_name = model.get_model_name()\n",
    "    printlog(info=get_print_info(gait_or_motion, motion_type, subjects_list_global), time=False, line_break=False)\n",
    "    \n",
    "    ## 开始训练和测试\n",
    "    for subject_order in range(len(subjects_list_global)):\n",
    "        subject = subjects_list_global[subject_order]\n",
    "        file_name, class_weights, encoded_label_name, raw_label_type, true_labels  = get_fileName_weights(file_path, gait_or_motion, motion_type, subject, subjects_list_global)\n",
    "        basic_save_path = os.path.join(os.path.dirname(os.getcwd()) , 'results', 'Intra-Subject', '2-CNNs-BackBoneTest')\n",
    "        save_path = get_save_path(basic_save_path, gait_or_motion, motion_type, model_name, subject)\n",
    "        print('保存结果的绝对路径： ', save_path['absolute_path'])\n",
    "        print('保存结果的相对路径： ', save_path['relative_path'])\n",
    "        \n",
    "        callbacks['weights'] = class_weights\n",
    "        train_test_utils['confusion_matrix']['params']['label_type'] = raw_label_type\n",
    "        \n",
    "        for exp_tim in range(total_exp_time):\n",
    "            clear()\n",
    "            current_exp_time = exp_tim + 1\n",
    "            settings_dict['current_exp_time'] = current_exp_time\n",
    "            printlog(info='当前模型：%s'% model_name, time=True, line_break=False)\n",
    "            printlog(info='当前受试者编号：%s' % subject, time=True, line_break=False)\n",
    "            printlog(info='当前实验次数：%d / %d' % (current_exp_time, total_exp_time), time=True, line_break=False)\n",
    "            train_loader, valid_loader, test_loader = get_intra_dataloaders(file_name, data_list, feature_list, encoded_label_name, total_exp_time,gait_or_motion, current_exp_time, train_batch, test_batch, valid_batch, train_test_utils['hmm_tools']['gait_dataset_divide_mode'])\n",
    "            if gait_or_motion == 'gait':\n",
    "                print('步态数据集划分方式： ', train_test_utils['hmm_tools']['gait_dataset_divide_mode'])\n",
    "            print('Sample size of train set, valid set and test set are: ', len(train_loader.dataset), len(valid_loader.dataset), len(test_loader.dataset))\n",
    "            model = GeneralCNNs(network_branch, gait_or_motion, motion_type, conv_type=conv_type)\n",
    "            model.double()\n",
    "            model.to(device=device)\n",
    "            train_test_intra_model(settings_dict, model, train_loader, valid_loader, test_loader, device, save_path, callbacks, train_test_utils, true_labels)\n",
    "            \n",
    "    # 当一个模型针对所有受试者全部训练测试后， 计算保存所有受试者的平均结果\n",
    "    # 新增一个记录所有受试者的所有测试结果的df1\n",
    "    df1_metrics = []\n",
    "    df2_metrics_mean = []\n",
    "    df2_metrics_std = []\n",
    "    printlog(info='当前模型：%s' % model_name, time=True, line_break=True)\n",
    "    basic_file_path = os.path.join(os.path.dirname(os.getcwd()) , 'results', 'Intra-Subject', '2-CNNs-BackBoneTest')\n",
    "    \n",
    "    for subject_order in range(len(subjects_list_global)):\n",
    "        subject = subjects_list_global[subject_order]\n",
    "        metrics_file_path = get_save_path(basic_file_path, gait_or_motion, motion_type, model_name, subject)\n",
    "        metrics_file_name = os.path.join(metrics_file_path['absolute_path'], 'test_metrics.csv')\n",
    "        # 判断文件是否存在\n",
    "        if not os.path.exists(metrics_file_name):\n",
    "            print(\"受试者：%s 的文件: %s， 不存在！\" %(subject, metrics_file_name))\n",
    "        else:\n",
    "            # 读取每个受试者的test_metrics\n",
    "            print(\"读取受试者：%s 的test_metrics: \" %subject)\n",
    "            df = pd.read_csv(metrics_file_name, header=0, index_col=0)\n",
    "            # ignore_index=True参数用于重置索引，以确保索引是连续的\n",
    "            df1_metrics.extend(df.T.values[:-2, :])\n",
    "            df2_metrics_mean.append(df.T.values[-2, :])\n",
    "            df2_metrics_std.append(df.T.values[-1, :])\n",
    "        \n",
    "    printlog(info='当前模型：%s, 保存所有受试者所有测试指标的平均结果' % model_name, time=False, line_break=False)\n",
    "    df1 = pd.DataFrame(df1_metrics, index=range(1, len(df1_metrics) + 1), columns=df.index)\n",
    "    # 计算平均值并添加到DataFrame\n",
    "    mean_row = df1.mean().to_frame().T  # 转换为DataFrame并进行转置\n",
    "    mean_row.index = ['mean']  # 设置索引名称\n",
    "    df1 = pd.concat([df1, mean_row])\n",
    "    # 计算标准差并添加到DataFrame\n",
    "    std_row = df1[:-1].std().to_frame().T  # 转换为DataFrame并进行转置，排除最后一行(mean行)来计算标准差\n",
    "    std_row.index = ['std']  # 设置索引名称\n",
    "    df1 = pd.concat([df1, std_row]).round(3)\n",
    "    # 保存df1  \n",
    "    dfs_save_path = os.path.dirname(metrics_file_path['absolute_path'])\n",
    "    df1_save_name = os.path.join(dfs_save_path, 'all_metrics_averaged_results.csv')\n",
    "    df1.to_csv(df1_save_name, index=True)\n",
    "    \n",
    "    printlog(info='当前模型：%s, 保存单个受试者测试指标平均的平均结果' % model_name, time=False, line_break=False)\n",
    "    # 保存df2\n",
    "    df2_metrics_mean, df2_metrics_std = np.round(np.array(df2_metrics_mean), 3), np.round(np.array(df2_metrics_std), 3)\n",
    "    df2_metrics = np.array([str(df2_metrics_mean[i, j]) +'+'+ str(df2_metrics_std[i, j]) for i in range(df2_metrics_mean.shape[0]) for j in range(df2_metrics_mean.shape[1])])\n",
    "    df2_metrics = df2_metrics.reshape(df2_metrics_mean.shape)\n",
    "    df2 = pd.DataFrame(df2_metrics, index=['Sub'+i for i in subjects_list_global], columns=df.index)\n",
    "    # 计算平均值并添加到DataFrame\n",
    "    mean_row = np.round(np.mean(df2_metrics_mean, axis=0), 3)\n",
    "    std_row = np.round(np.std(df2_metrics_mean, axis=0), 3)\n",
    "    df2.loc['mean'] = mean_row\n",
    "    df2.loc['std'] = std_row\n",
    "    df2_save_name = os.path.join(dfs_save_path, 'alone_subject_averaged_results.csv')\n",
    "    df2.to_csv(df2_save_name, index=True)\n",
    "    \n",
    "    if gait_or_motion == 'gait' and train_test_utils['hmm_tools']['use_hmm']:\n",
    "        ## test_metrics——hmm.csv处理\n",
    "        # 新增一个记录所有受试者的所有测试结果的df1\n",
    "        df1_metrics = []\n",
    "        df2_metrics_mean = []\n",
    "        df2_metrics_std = []\n",
    "        for subject_order in range(len(subjects_list_global)):\n",
    "            subject = subjects_list_global[subject_order]\n",
    "            metrics_file_path = get_save_path(basic_file_path, gait_or_motion, motion_type, model_name, subject)\n",
    "            metrics_file_name = os.path.join(metrics_file_path['absolute_path'], 'test_metrics_hmm.csv')\n",
    "            # 判断文件是否存在\n",
    "            if not os.path.exists(metrics_file_name):\n",
    "                print(\"受试者：%s 的文件: %s， 不存在！\" %(subject, metrics_file_name))\n",
    "            else:\n",
    "                # 读取每个受试者的test_metrics\n",
    "                print(\"读取受试者：%s 的test_metrics_hmm: \" %subject)\n",
    "                df = pd.read_csv(metrics_file_name, header=0, index_col=0)\n",
    "                # ignore_index=True参数用于重置索引，以确保索引是连续的\n",
    "                df1_metrics.extend(df.T.values[:-2, :])\n",
    "                df2_metrics_mean.append(df.T.values[-2, :])\n",
    "                df2_metrics_std.append(df.T.values[-1, :])\n",
    "        \n",
    "        printlog(info='当前模型：%s, 保存所有受试者所有测试指标的平均结果' % model_name, time=False, line_break=False)\n",
    "        df1 = pd.DataFrame(df1_metrics, index=range(1, len(df1_metrics) + 1), columns=df.index)\n",
    "        # 计算平均值并添加到DataFrame\n",
    "        mean_row = df1.mean().to_frame().T  # 转换为DataFrame并进行转置\n",
    "        mean_row.index = ['mean']  # 设置索引名称\n",
    "        df1 = pd.concat([df1, mean_row])\n",
    "        # 计算标准差并添加到DataFrame\n",
    "        std_row = df1[:-1].std().to_frame().T  # 转换为DataFrame并进行转置，排除最后一行(mean行)来计算标准差\n",
    "        std_row.index = ['std']  # 设置索引名称\n",
    "        df1 = pd.concat([df1, std_row]).round(3)\n",
    "        # 保存df1  \n",
    "        dfs_save_path = os.path.dirname(metrics_file_path['absolute_path'])\n",
    "        df1_save_name = os.path.join(dfs_save_path, 'all_metrics_averaged_results_hmm.csv')\n",
    "        df1.to_csv(df1_save_name, index=True)\n",
    "        \n",
    "        printlog(info='当前模型：%s, 保存单个受试者测试指标平均的平均结果' % model_name, time=False, line_break=False)\n",
    "        # 保存df2\n",
    "        df2_metrics_mean, df2_metrics_std = np.round(np.array(df2_metrics_mean), 3), np.round(np.array(df2_metrics_std), 3)\n",
    "        df2_metrics = np.array([str(df2_metrics_mean[i, j]) +'+'+ str(df2_metrics_std[i, j]) for i in range(df2_metrics_mean.shape[0]) for j in range(df2_metrics_mean.shape[1])])\n",
    "        df2_metrics = df2_metrics.reshape(df2_metrics_mean.shape)\n",
    "        df2 = pd.DataFrame(df2_metrics, index=['Sub'+i for i in subjects_list_global], columns=df.index)\n",
    "        # 计算平均值并添加到DataFrame\n",
    "        mean_row = np.round(np.mean(df2_metrics_mean, axis=0), 3)\n",
    "        std_row = np.round(np.std(df2_metrics_mean, axis=0), 3)\n",
    "        df2.loc['mean'] = mean_row\n",
    "        df2.loc['std'] = std_row\n",
    "        df2_save_name = os.path.join(dfs_save_path, 'alone_subject_averaged_results_hmm.csv')\n",
    "        df2.to_csv(df2_save_name, index=True)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## 2. 以下为测试不同损失函数的代码\n",
    "\"\"\"\n",
    "settings_dict = {'total_exp_time': total_exp_time, 'network_branch': network_branch}\n",
    "conv_types = ['Conv']\n",
    "criterions = ['CE', 'WeightedCE', 'FL', 'WeightedFL', 'AttenuationWeightedCE', 'AttenuationWeightedFL']\n",
    "\n",
    "for criterion in criterions:\n",
    "    callbacks['criterion']['loss_type'] = criterion\n",
    "    for conv_type in conv_types:\n",
    "        model = GeneralCNNs(network_branch, gait_or_motion, motion_type, conv_type=conv_type)\n",
    "        model_name = model.get_model_name()\n",
    "        printlog(info=get_print_info(gait_or_motion, motion_type, subjects_list_global), time=False, line_break=False)\n",
    "        basic_save_path = os.path.join(os.path.dirname(os.getcwd()) , 'results', 'Intra-Subject', '3-CNNs-LossFunctionTest', criterion)\n",
    "        \n",
    "        ## 开始训练和测试\n",
    "        for subject_order in range(len(subjects_list_global)):\n",
    "            subject = subjects_list_global[subject_order]\n",
    "            file_name, class_weights, encoded_label_name, raw_label_type, true_labels  = get_fileName_weights(file_path, gait_or_motion, motion_type, subject, subjects_list_global)\n",
    "            save_path = get_save_path(basic_save_path, gait_or_motion, motion_type, model_name, subject)\n",
    "            print('保存结果的绝对路径： ', save_path['absolute_path'])\n",
    "            print('保存结果的相对路径： ', save_path['relative_path'])\n",
    "            \n",
    "            callbacks['weights'] = class_weights\n",
    "            train_test_utils['confusion_matrix']['params']['label_type'] = raw_label_type\n",
    "            \n",
    "            for exp_tim in range(total_exp_time):\n",
    "                clear()\n",
    "                current_exp_time = exp_tim + 1\n",
    "                settings_dict['current_exp_time'] = current_exp_time\n",
    "                printlog(info='当前模型：%s'% model_name, time=True, line_break=False)\n",
    "                printlog(info='当前受试者编号：%s' % subject, time=True, line_break=False)\n",
    "                printlog(info='当前实验次数：%d / %d' % (current_exp_time, total_exp_time), time=True, line_break=False)\n",
    "                train_loader, valid_loader, test_loader = get_intra_dataloaders(file_name, data_list, feature_list, encoded_label_name, total_exp_time,gait_or_motion, current_exp_time, train_batch, test_batch, valid_batch, train_test_utils['hmm_tools']['gait_dataset_divide_mode'])\n",
    "                if gait_or_motion == 'gait':\n",
    "                    print('步态数据集划分方式： ', train_test_utils['hmm_tools']['gait_dataset_divide_mode'])\n",
    "                print('Sample size of train set, valid set and test set are: ', len(train_loader.dataset), len(valid_loader.dataset), len(test_loader.dataset))\n",
    "                model = GeneralCNNs(network_branch, gait_or_motion, motion_type, conv_type=conv_type)\n",
    "                model.double()\n",
    "                model.to(device=device)\n",
    "                train_test_intra_model(settings_dict, model, train_loader, valid_loader, test_loader, device, save_path, callbacks, train_test_utils, true_labels)\n",
    "\n",
    "        # 当一个模型针对所有受试者全部训练测试后， 计算保存所有受试者的平均结果\n",
    "        # 新增一个记录所有受试者的所有测试结果的df1\n",
    "        df1_metrics = []\n",
    "        df2_metrics_mean = []\n",
    "        df2_metrics_std = []\n",
    "        basic_file_path = os.path.join(os.path.dirname(os.getcwd()) , 'results', 'Intra-Subject', '3-CNNs-LossFunctionTest', criterion)\n",
    "        printlog(info='当前模型：%s' % model_name, time=True, line_break=True)\n",
    "        \n",
    "        for subject_order in range(len(subjects_list_global)):\n",
    "            subject = subjects_list_global[subject_order]\n",
    "            metrics_file_path = get_save_path(basic_file_path, gait_or_motion, motion_type, model_name, subject)\n",
    "            metrics_file_name = os.path.join(metrics_file_path['absolute_path'], 'test_metrics.csv')\n",
    "            # 判断文件是否存在\n",
    "            if not os.path.exists(metrics_file_name):\n",
    "                print(\"受试者：%s 的文件: %s， 不存在！\" %(subject, metrics_file_name))\n",
    "            else:\n",
    "                # 读取每个受试者的test_metrics\n",
    "                print(\"读取受试者：%s 的test_metrics: \" %subject)\n",
    "                df = pd.read_csv(metrics_file_name, header=0, index_col=0)\n",
    "                # ignore_index=True参数用于重置索引，以确保索引是连续的\n",
    "                df1_metrics.extend(df.T.values[:-2, :])\n",
    "                df2_metrics_mean.append(df.T.values[-2, :])\n",
    "                df2_metrics_std.append(df.T.values[-1, :])\n",
    "\n",
    "        printlog(info='当前模型：%s, 保存所有受试者所有测试指标的平均结果' % model_name, time=False, line_break=False)\n",
    "        df1 = pd.DataFrame(df1_metrics, index=range(1, len(df1_metrics) + 1), columns=df.index)\n",
    "        # 计算平均值并添加到DataFrame\n",
    "        mean_row = df1.mean().to_frame().T  # 转换为DataFrame并进行转置\n",
    "        mean_row.index = ['mean']  # 设置索引名称\n",
    "        df1 = pd.concat([df1, mean_row])\n",
    "        # 计算标准差并添加到DataFrame\n",
    "        std_row = df1[:-1].std().to_frame().T  # 转换为DataFrame并进行转置，排除最后一行(mean行)来计算标准差\n",
    "        std_row.index = ['std']  # 设置索引名称\n",
    "        df1 = pd.concat([df1, std_row]).round(3)\n",
    "        # 保存df1  \n",
    "        dfs_save_path = os.path.dirname(metrics_file_path['absolute_path'])\n",
    "        df1_save_name = os.path.join(dfs_save_path, 'all_metrics_averaged_results.csv')\n",
    "        df1.to_csv(df1_save_name, index=True)\n",
    "\n",
    "        printlog(info='当前模型：%s, 保存单个受试者测试指标平均的平均结果' % model_name, time=False, line_break=False)\n",
    "        # 保存df2\n",
    "        df2_metrics_mean, df2_metrics_std = np.round(np.array(df2_metrics_mean), 3), np.round(np.array(df2_metrics_std), 3)\n",
    "        df2_metrics = np.array([str(df2_metrics_mean[i, j]) +'+'+ str(df2_metrics_std[i, j]) for i in range(df2_metrics_mean.shape[0]) for j in range(df2_metrics_mean.shape[1])])\n",
    "        df2_metrics = df2_metrics.reshape(df2_metrics_mean.shape)\n",
    "        df2 = pd.DataFrame(df2_metrics, index=['Sub'+i for i in subjects_list_global], columns=df.index)\n",
    "        # 计算平均值并添加到DataFrame\n",
    "        mean_row = np.round(np.mean(df2_metrics_mean, axis=0), 3)\n",
    "        std_row = np.round(np.std(df2_metrics_mean, axis=0), 3)\n",
    "        df2.loc['mean'] = mean_row\n",
    "        df2.loc['std'] = std_row\n",
    "        df2_save_name = os.path.join(dfs_save_path, 'alone_subject_averaged_results.csv')\n",
    "        df2.to_csv(df2_save_name, index=True)\n",
    "\n",
    "        if gait_or_motion == 'gait' and train_test_utils['hmm_tools']['use_hmm']:\n",
    "            ## test_metrics——hmm.csv处理\n",
    "            # 新增一个记录所有受试者的所有测试结果的df1\n",
    "            df1_metrics = []\n",
    "            df2_metrics_mean = []\n",
    "            df2_metrics_std = []\n",
    "            for subject_order in range(len(subjects_list_global)):\n",
    "                subject = subjects_list_global[subject_order]\n",
    "                metrics_file_path = get_save_path(basic_file_path, gait_or_motion, motion_type, model_name, subject)\n",
    "                metrics_file_name = os.path.join(metrics_file_path['absolute_path'], 'test_metrics_hmm.csv')\n",
    "                # 判断文件是否存在\n",
    "                if not os.path.exists(metrics_file_name):\n",
    "                    print(\"受试者：%s 的文件: %s， 不存在！\" %(subject, metrics_file_name))\n",
    "                else:\n",
    "                    # 读取每个受试者的test_metrics\n",
    "                    print(\"读取受试者：%s 的test_metrics_hmm: \" %subject)\n",
    "                    df = pd.read_csv(metrics_file_name, header=0, index_col=0)\n",
    "                    # ignore_index=True参数用于重置索引，以确保索引是连续的\n",
    "                    df1_metrics.extend(df.T.values[:-2, :])\n",
    "                    df2_metrics_mean.append(df.T.values[-2, :])\n",
    "                    df2_metrics_std.append(df.T.values[-1, :])\n",
    "\n",
    "            printlog(info='当前模型：%s, 保存所有受试者所有测试指标的平均结果' % model_name, time=False, line_break=False)\n",
    "            df1 = pd.DataFrame(df1_metrics, index=range(1, len(df1_metrics) + 1), columns=df.index)\n",
    "            # 计算平均值并添加到DataFrame\n",
    "            mean_row = df1.mean().to_frame().T  # 转换为DataFrame并进行转置\n",
    "            mean_row.index = ['mean']  # 设置索引名称\n",
    "            df1 = pd.concat([df1, mean_row])\n",
    "            # 计算标准差并添加到DataFrame\n",
    "            std_row = df1[:-1].std().to_frame().T  # 转换为DataFrame并进行转置，排除最后一行(mean行)来计算标准差\n",
    "            std_row.index = ['std']  # 设置索引名称\n",
    "            df1 = pd.concat([df1, std_row]).round(3)\n",
    "            # 保存df1  \n",
    "            dfs_save_path = os.path.dirname(metrics_file_path['absolute_path'])\n",
    "            df1_save_name = os.path.join(dfs_save_path, 'all_metrics_averaged_results_hmm.csv')\n",
    "            df1.to_csv(df1_save_name, index=True)\n",
    "\n",
    "            printlog(info='当前模型：%s, 保存单个受试者测试指标平均的平均结果' % model_name, time=False, line_break=False)\n",
    "            # 保存df2\n",
    "            df2_metrics_mean, df2_metrics_std = np.round(np.array(df2_metrics_mean), 3), np.round(np.array(df2_metrics_std), 3)\n",
    "            df2_metrics = np.array([str(df2_metrics_mean[i, j]) +'+'+ str(df2_metrics_std[i, j]) for i in range(df2_metrics_mean.shape[0]) for j in range(df2_metrics_mean.shape[1])])\n",
    "            df2_metrics = df2_metrics.reshape(df2_metrics_mean.shape)\n",
    "            df2 = pd.DataFrame(df2_metrics, index=['Sub'+i for i in subjects_list_global], columns=df.index)\n",
    "            # 计算平均值并添加到DataFrame\n",
    "            mean_row = np.round(np.mean(df2_metrics_mean, axis=0), 3)\n",
    "            std_row = np.round(np.std(df2_metrics_mean, axis=0), 3)\n",
    "            df2.loc['mean'] = mean_row\n",
    "            df2.loc['std'] = std_row\n",
    "            df2_save_name = os.path.join(dfs_save_path, 'alone_subject_averaged_results_hmm.csv')\n",
    "            df2.to_csv(df2_save_name, index=True)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## 3. 以下为测试与先进方法对比中的不同BackBone的代码\n",
    "total_exp_time = 5\n",
    "network_branch = 1\n",
    "settings_dict = {'total_exp_time': total_exp_time, 'network_branch': network_branch}\n",
    "data_params = {'gait_or_motion': ['motion', 'gait', 'gait', 'gait'],\n",
    "               'motion_type': ['WAK', 'WAK', 'UPS', 'DNS']}\n",
    "criterion = 'AttenuationWeightedCE'\n",
    "callbacks['criterion']['loss_type'] = criterion\n",
    "callbacks['early_stopping']['params']['patience'] = 20\n",
    "\n",
    "# 要更改的参数\n",
    "conv_types = ['DNN', 'Conv', 'ResNetV2', 'MobileNetV3', 'SKConv']\n",
    "train_test_utils['confusion_matrix']['get_cm'] = True\n",
    "train_test_utils['tsne_visualization']['get_tsne'] = False\n",
    "\n",
    "for index in range(len(data_params['gait_or_motion'])):\n",
    "    gait_or_motion = data_params['gait_or_motion'][index]\n",
    "    motion_type = data_params['motion_type'][index]\n",
    "    \n",
    "    for conv_type in conv_types:\n",
    "        model = GeneralCNNs(network_branch, gait_or_motion, motion_type, conv_type=conv_type)\n",
    "        model_name = model.get_model_name()\n",
    "        printlog(info=get_print_info(gait_or_motion, motion_type, subjects_list_global), time=False, line_break=False)\n",
    "        \n",
    "        ## 开始训练和测试\n",
    "        for subject_order in range(len(subjects_list_global)):\n",
    "            subject = subjects_list_global[subject_order]\n",
    "            file_name, class_weights, encoded_label_name, raw_label_type, true_labels  = get_fileName_weights(file_path, gait_or_motion, motion_type, subject, subjects_list_global)\n",
    "            basic_save_path = os.path.join(os.path.dirname(os.getcwd()) , 'results', 'Intra-Subject', '11-Start-of-the-artMethodsComparison', criterion)\n",
    "            save_path = get_save_path(basic_save_path, gait_or_motion, motion_type, model_name, subject)\n",
    "            print('保存结果的绝对路径： ', save_path['absolute_path'])\n",
    "            print('保存结果的相对路径： ', save_path['relative_path'])\n",
    "            \n",
    "            callbacks['weights'] = class_weights\n",
    "            train_test_utils['confusion_matrix']['params']['label_type'] = raw_label_type\n",
    "            \n",
    "            for exp_tim in range(total_exp_time):\n",
    "                clear()\n",
    "                current_exp_time = exp_tim + 1\n",
    "                settings_dict['current_exp_time'] = current_exp_time\n",
    "                printlog(info='当前模型：%s'% model_name, time=True, line_break=False)\n",
    "                print('损失函数: %s'% criterion)\n",
    "                printlog(info='当前受试者编号：%s' % subject, time=True, line_break=False)\n",
    "                printlog(info='当前实验次数：%d / %d' % (current_exp_time, total_exp_time), time=True, line_break=False)\n",
    "                train_loader, valid_loader, test_loader = get_intra_dataloaders(file_name, data_list, feature_list, encoded_label_name, total_exp_time,gait_or_motion, current_exp_time, train_batch, test_batch, valid_batch, train_test_utils['hmm_tools']['gait_dataset_divide_mode'])\n",
    "                if gait_or_motion == 'gait':\n",
    "                    print('步态数据集划分方式： ', train_test_utils['hmm_tools']['gait_dataset_divide_mode'])\n",
    "                print('Sample size of train set, valid set and test set are: ', len(train_loader.dataset), len(valid_loader.dataset), len(test_loader.dataset))\n",
    "                model = GeneralCNNs(network_branch, gait_or_motion, motion_type, conv_type=conv_type)\n",
    "                model.double()\n",
    "                model.to(device=device)\n",
    "                train_test_intra_model(settings_dict, model, train_loader, valid_loader, test_loader, device, save_path, callbacks, train_test_utils, true_labels)\n",
    "                \n",
    "        # 当一个模型针对所有受试者全部训练测试后， 计算保存所有受试者的平均结果\n",
    "        # 新增一个记录所有受试者的所有测试结果的df1\n",
    "        df1_metrics = []\n",
    "        df2_metrics_mean = []\n",
    "        df2_metrics_std = []\n",
    "        printlog(info='当前模型：%s' % model_name, time=True, line_break=True)\n",
    "        basic_file_path = os.path.join(os.path.dirname(os.getcwd()) , 'results', 'Intra-Subject', '11-Start-of-the-artMethodsComparison', criterion)\n",
    "        \n",
    "        for subject_order in range(len(subjects_list_global)):\n",
    "            subject = subjects_list_global[subject_order]\n",
    "            metrics_file_path = get_save_path(basic_file_path, gait_or_motion, motion_type, model_name, subject)\n",
    "            metrics_file_name = os.path.join(metrics_file_path['absolute_path'], 'test_metrics.csv')\n",
    "            # 判断文件是否存在\n",
    "            if not os.path.exists(metrics_file_name):\n",
    "                print(\"受试者：%s 的文件: %s， 不存在！\" %(subject, metrics_file_name))\n",
    "            else:\n",
    "                # 读取每个受试者的test_metrics\n",
    "                print(\"读取受试者：%s 的test_metrics: \" %subject)\n",
    "                df = pd.read_csv(metrics_file_name, header=0, index_col=0)\n",
    "                # ignore_index=True参数用于重置索引，以确保索引是连续的\n",
    "                df1_metrics.extend(df.T.values[:-2, :])\n",
    "                df2_metrics_mean.append(df.T.values[-2, :])\n",
    "                df2_metrics_std.append(df.T.values[-1, :])\n",
    "            \n",
    "        printlog(info='当前模型：%s, 保存所有受试者所有测试指标的平均结果' % model_name, time=False, line_break=False)\n",
    "        df1 = pd.DataFrame(df1_metrics, index=range(1, len(df1_metrics) + 1), columns=df.index)\n",
    "        # 计算平均值并添加到DataFrame\n",
    "        mean_row = df1.mean().to_frame().T  # 转换为DataFrame并进行转置\n",
    "        mean_row.index = ['mean']  # 设置索引名称\n",
    "        df1 = pd.concat([df1, mean_row])\n",
    "        # 计算标准差并添加到DataFrame\n",
    "        std_row = df1[:-1].std().to_frame().T  # 转换为DataFrame并进行转置，排除最后一行(mean行)来计算标准差\n",
    "        std_row.index = ['std']  # 设置索引名称\n",
    "        df1 = pd.concat([df1, std_row]).round(3)\n",
    "        # 保存df1  \n",
    "        dfs_save_path = os.path.dirname(metrics_file_path['absolute_path'])\n",
    "        df1_save_name = os.path.join(dfs_save_path, 'all_metrics_averaged_results.csv')\n",
    "        df1.to_csv(df1_save_name, index=True)\n",
    "        \n",
    "        printlog(info='当前模型：%s, 保存单个受试者测试指标平均的平均结果' % model_name, time=False, line_break=False)\n",
    "        # 保存df2\n",
    "        df2_metrics_mean, df2_metrics_std = np.round(np.array(df2_metrics_mean), 3), np.round(np.array(df2_metrics_std), 3)\n",
    "        df2_metrics = np.array([str(df2_metrics_mean[i, j]) +'+'+ str(df2_metrics_std[i, j]) for i in range(df2_metrics_mean.shape[0]) for j in range(df2_metrics_mean.shape[1])])\n",
    "        df2_metrics = df2_metrics.reshape(df2_metrics_mean.shape)\n",
    "        df2 = pd.DataFrame(df2_metrics, index=['Sub'+i for i in subjects_list_global], columns=df.index)\n",
    "        # 计算平均值并添加到DataFrame\n",
    "        mean_row = np.round(np.mean(df2_metrics_mean, axis=0), 3)\n",
    "        std_row = np.round(np.std(df2_metrics_mean, axis=0), 3)\n",
    "        df2.loc['mean'] = mean_row\n",
    "        df2.loc['std'] = std_row\n",
    "        df2_save_name = os.path.join(dfs_save_path, 'alone_subject_averaged_results.csv')\n",
    "        df2.to_csv(df2_save_name, index=True)\n",
    "        \n",
    "        if gait_or_motion == 'gait' and train_test_utils['hmm_tools']['use_hmm']:\n",
    "            ## test_metrics——hmm.csv处理\n",
    "            # 新增一个记录所有受试者的所有测试结果的df1\n",
    "            df1_metrics = []\n",
    "            df2_metrics_mean = []\n",
    "            df2_metrics_std = []\n",
    "            for subject_order in range(len(subjects_list_global)):\n",
    "                subject = subjects_list_global[subject_order]\n",
    "                metrics_file_path = get_save_path(basic_file_path, gait_or_motion, motion_type, model_name, subject)\n",
    "                metrics_file_name = os.path.join(metrics_file_path['absolute_path'], 'test_metrics_hmm.csv')\n",
    "                # 判断文件是否存在\n",
    "                if not os.path.exists(metrics_file_name):\n",
    "                    print(\"受试者：%s 的文件: %s， 不存在！\" %(subject, metrics_file_name))\n",
    "                else:\n",
    "                    # 读取每个受试者的test_metrics\n",
    "                    print(\"读取受试者：%s 的test_metrics_hmm: \" %subject)\n",
    "                    df = pd.read_csv(metrics_file_name, header=0, index_col=0)\n",
    "                    # ignore_index=True参数用于重置索引，以确保索引是连续的\n",
    "                    df1_metrics.extend(df.T.values[:-2, :])\n",
    "                    df2_metrics_mean.append(df.T.values[-2, :])\n",
    "                    df2_metrics_std.append(df.T.values[-1, :])\n",
    "            \n",
    "            printlog(info='当前模型：%s, 保存所有受试者所有测试指标的平均结果' % model_name, time=False, line_break=False)\n",
    "            df1 = pd.DataFrame(df1_metrics, index=range(1, len(df1_metrics) + 1), columns=df.index)\n",
    "            # 计算平均值并添加到DataFrame\n",
    "            mean_row = df1.mean().to_frame().T  # 转换为DataFrame并进行转置\n",
    "            mean_row.index = ['mean']  # 设置索引名称\n",
    "            df1 = pd.concat([df1, mean_row])\n",
    "            # 计算标准差并添加到DataFrame\n",
    "            std_row = df1[:-1].std().to_frame().T  # 转换为DataFrame并进行转置，排除最后一行(mean行)来计算标准差\n",
    "            std_row.index = ['std']  # 设置索引名称\n",
    "            df1 = pd.concat([df1, std_row]).round(3)\n",
    "            # 保存df1  \n",
    "            dfs_save_path = os.path.dirname(metrics_file_path['absolute_path'])\n",
    "            df1_save_name = os.path.join(dfs_save_path, 'all_metrics_averaged_results_hmm.csv')\n",
    "            df1.to_csv(df1_save_name, index=True)\n",
    "            \n",
    "            printlog(info='当前模型：%s, 保存单个受试者测试指标平均的平均结果' % model_name, time=False, line_break=False)\n",
    "            # 保存df2\n",
    "            df2_metrics_mean, df2_metrics_std = np.round(np.array(df2_metrics_mean), 3), np.round(np.array(df2_metrics_std), 3)\n",
    "            df2_metrics = np.array([str(df2_metrics_mean[i, j]) +'+'+ str(df2_metrics_std[i, j]) for i in range(df2_metrics_mean.shape[0]) for j in range(df2_metrics_mean.shape[1])])\n",
    "            df2_metrics = df2_metrics.reshape(df2_metrics_mean.shape)\n",
    "            df2 = pd.DataFrame(df2_metrics, index=['Sub'+i for i in subjects_list_global], columns=df.index)\n",
    "            # 计算平均值并添加到DataFrame\n",
    "            mean_row = np.round(np.mean(df2_metrics_mean, axis=0), 3)\n",
    "            std_row = np.round(np.std(df2_metrics_mean, axis=0), 3)\n",
    "            df2.loc['mean'] = mean_row\n",
    "            df2.loc['std'] = std_row\n",
    "            df2_save_name = os.path.join(dfs_save_path, 'alone_subject_averaged_results_hmm.csv')\n",
    "            df2.to_csv(df2_save_name, index=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pytorch",
   "language": "python",
   "display_name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
